{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main CNN model for bat call classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-18 14:29:23.348551: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-18 14:29:23.705908: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-18 14:29:23.705945: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-18 14:29:24.814716: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-18 14:29:24.814817: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-18 14:29:24.814826: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from typing import Callable\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "import math\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to track execution time of certain code events\n",
    "class track_time:\n",
    "    def __init__(self):\n",
    "        self.events = []\n",
    "        self.add('Start')\n",
    "    def add(self, name: str) -> None:\n",
    "        if name == \"total\":\n",
    "            raise RuntimeError(\"Cant use the name 'total'.\")\n",
    "        self.events.append([name,time.time()])\n",
    "    def get_time(self): # calculate time between events and total\n",
    "        self.timed_events = {}\n",
    "        for (n, event) in enumerate(self.events):\n",
    "            elapsed_time = 0\n",
    "            if n+1 == len(self.events):\n",
    "                # last element\n",
    "                elapsed_time = time.time() - event[1]\n",
    "            else:\n",
    "                elapsed_time = self.events[n+1][1] - event[1]\n",
    "            self.timed_events[event[0]] = elapsed_time\n",
    "        self.timed_events['total'] = time.time() - self.events[0][1]\n",
    "        return self.timed_events\n",
    "    def __str__(self):\n",
    "        output = \"\"\n",
    "        if not hasattr(self,'timed_events'):\n",
    "            self.get_time()\n",
    "        output += (\"  Event tracked  |  Duration  \\n\")\n",
    "        output += (\"==============================\\n\")\n",
    "        for name,duration in self.timed_events.items():\n",
    "            output += (\" \"+name+\"\\t\\t\\t| \"+str(round(duration,3))+\"\\n\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer\n",
    "timer = track_time()\n",
    "timer.add(\"Read in data\")\n",
    "# load image data s and reshape \n",
    "data = pd.read_pickle('images_df_numerical.pkl')\n",
    "# convert to numpy array\n",
    "X, y = data['data'], data['Species']\n",
    "classes = X.unique()\n",
    "image_size = X[0].size\n",
    "samples = X.size\n",
    "image_shape = (216,334,3) # height, width , channel\n",
    "# reshape every row to the image, swap rgbs and scale to 0-1\n",
    "X = [\n",
    "    cv2.cvtColor(row.reshape(image_shape), cv2.COLOR_BGR2RGB).astype('float32')/255. \n",
    "    for row in X]\n",
    "y = [row.astype('int32') for row in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timer.add(\"Split Train/Test\")\n",
    "# Cross Valiadation, wenn wir ein \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "X_val = np.array(X_val)\n",
    "y_val = np.array(y_val)\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "number_of_classes = classes.size()\n",
    "pooling_size = (2, 2)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=20, min_delta=0.001, start_from_epoch=15, restore_best_weights=True)\n",
    "padding = \"same\"\n",
    "epochs = 200\n",
    "dropout_rate = 1 - 0.8 # ggf anpassen, wenn overfittet\n",
    "\n",
    "def create_model(conv_kernel_sizes: list, conv_filter_nums: list, number_of_neurons: list, optimizer=\"adam\", activation_function=\"relu\") -> tf.model:\n",
    "    f1 = F1Score(num_classes=number_of_classes, average=\"micro\")\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(conv_filter_nums[0], conv_kernel_sizes[0],activation=activation_function,input_shape=image_shape,padding=padding))\n",
    "    model.add(MaxPool2D(pooling_size))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(conv_filter_nums[1],conv_kernel_sizes[1],activation=activation_function, padding=padding))\n",
    "    model.add(MaxPool2D(pooling_size))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Classficiation\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(number_of_neurons[0], activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(number_of_neurons[1], activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(number_of_neurons[2], activation=activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output-Layer\n",
    "    model.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "    model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\", f1])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "batch_sizes = [8, 16, 32, 64, 128]\n",
    "learning_rates = [0.0001, 0.001, 0.001]\n",
    "conv_kernel_sizes = [(7,7), (3, 3)] # schauen, ob ggf. wir mehr layer benutzen\n",
    "conv_filter_nums = [32, 64]\n",
    "number_of_neurons = [256, 128, 64]\n",
    "histories_with_params = list()\n",
    "\n",
    "for batch_size, learning_rate in product(batch_sizes, learning_rates):\n",
    "    model = create_model(conv_kernel_sizes, conv_filter_nums)\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        workers=8, # workers are number of cores\n",
    "        callbacks=[early_stopping],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1)\n",
    "    \n",
    "    parameters = {\"bs\": batch_size, \"lr\": learning_rate}\n",
    "\n",
    "    history_with_param = {\"history\": history, \"parameters\": parameters}\n",
    "    \n",
    "    histories_with_params.append(history_with_param)\n",
    "\n",
    "print(f\"Epochs: {len(history.history['accuracy'])}\")\n",
    "print(f\"Test Score: {round(model.evaluate(X_test, y_test)[1], 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = len(history.history[\"accuracy\"])\n",
    "\n",
    "for history_with_param in histories_with_params:\n",
    "    plt.plot(history_with_param[\"history\"].history[\"accuracy\"], label=\"train_data accuracy\")\n",
    "    plt.plot(history_with_param[\"history\"].history[\"val_accuracy\"], label=\"val_data accuracy\")\n",
    "    plt.scatter(number_of_epochs, model.evaluate(X_test, y_test)[1], label=\"test_data accuracy\", marker=\"x\", c=\"g\")\n",
    "    plt.title(f\"bs: {history_with_param[\"params\"][\"bs\"]} lr: {history_with_param[\"params\"][\"lr\"]}, Test Score: {round(model.evaluate(X_test, y_test)[1], 2)}%\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(f\"./testing/{history_with_param[\"params\"][\"bs\"]}_{history_with_param[\"params\"][\"lr\"]}.png\",dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
