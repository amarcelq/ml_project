{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main CNN model for bat call classification\n",
    "\n",
    "### **TO RUN THIS FILE**, just press the \"restart&execute\" button, and when the kernel dies, restart the notebook process, go to the `exit()` cell and execute all cells after that one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-25 19:26:11.076583: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-25 19:26:11.175407: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-12-25 19:26:11.175432: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-12-25 19:26:11.653859: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-25 19:26:11.653929: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-12-25 19:26:11.653936: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "from keras import backend as K \n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools_len as itertools\n",
    "from itertools_len import product\n",
    "import gc\n",
    "from tensorflow.keras.optimizers.legacy import Adam, SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from sklearn.model_selection import KFold\n",
    "from imblearn.over_sampling import SMOTE, ADASYN\n",
    "from imblearn.combine import SMOTEENN, SMOTETomek\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_model_optimization as tfmot\n",
    "import tempfile\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./data/images_df_numerical.pkl')\n",
    "\n",
    "def split_df_equal_class_distribution(df, batch_size):\n",
    "    \n",
    "    df['temp_id'] = range(len(df))\n",
    "    \n",
    "    num_batches = int(np.ceil(len(df) / batch_size))\n",
    "    \n",
    "    grouped = df.groupby('Species', group_keys=False)\n",
    "    \n",
    "    chunks = []\n",
    "    \n",
    "    for i in range(num_batches):\n",
    "        chunk = pd.DataFrame(columns=df.columns)\n",
    "        for _, group in grouped:\n",
    "            num_samples = int(batch_size * len(group) / len(df))\n",
    "            sample_indices = np.random.choice(group['temp_id'], size=num_samples, replace=False)\n",
    "            chunk = pd.concat([chunk, df[df['temp_id'].isin(sample_indices)]])\n",
    "        chunk = chunk.drop('temp_id', axis=1)\n",
    "        chunks.append(chunk)\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "chunk_size = 1000\n",
    "\n",
    "chunks_with_same_dist = split_df_equal_class_distribution(data, chunk_size)\n",
    "del data\n",
    "classes = chunks_with_same_dist[0][\"Species\"].unique()\n",
    "x_len = chunks_with_same_dist[0].iloc[0][\"data\"].size\n",
    "number_of_classes = classes.size\n",
    "most_x_in_one_class = chunks_with_same_dist[0][\"Species\"].value_counts().iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADASYN():  3    2302\n",
      "4    2270\n",
      "2    2261\n",
      "0    2260\n",
      "5    2256\n",
      "1    2235\n",
      "dtype: Int64\n"
     ]
    }
   ],
   "source": [
    "# Alleiniges undersampling wird keinen Sinn machen, da wir extrem wenig Datenpunkte overall haben\n",
    "def resample(resampler) -> tuple[np.array, np.array]:\n",
    "    # 0.3 as buffer\n",
    "    array_size = int(most_x_in_one_class * number_of_classes * (len(chunks_with_same_dist) + 0.3))\n",
    "    X = np.empty((array_size, x_len), dtype=np.uint8)\n",
    "    y = np.empty((array_size), dtype=np.uint8)\n",
    "\n",
    "    current_index = 0\n",
    "    for chunk in chunks_with_same_dist:\n",
    "        X_batch, y_batch = chunk['data'], chunk['Species']\n",
    "        X_batch, y_batch = np.stack(X_batch).astype(np.uint8), y_batch.astype(np.uint8)\n",
    "        X_resampled, y_resampled = resampler.fit_resample(X_batch, y_batch)\n",
    "        num_samples = X_resampled.shape[0]\n",
    "        X[current_index:current_index + num_samples] = X_resampled.astype(np.uint8)\n",
    "        y[current_index:current_index + num_samples] = y_resampled.astype(np.uint8)\n",
    "        current_index += num_samples\n",
    "\n",
    "    X.resize((current_index, X.shape[1]))\n",
    "    y.resize(current_index)\n",
    "    print(f\"{resampler}: \", pd.Series(y, dtype=pd.UInt8Dtype()).value_counts())\n",
    "\n",
    "    return X, y\n",
    "\n",
    "# oversampling\n",
    "smote = SMOTE()\n",
    "adasyn = ADASYN()\n",
    "\n",
    "X, y = resample(adasyn)\n",
    "\n",
    "# Kombination aus over und undersampling\n",
    "smoteenn = SMOTEENN()\n",
    "smotettomek = SMOTETomek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = X[0].size\n",
    "samples = X.size\n",
    "image_shape = (65, 100, 3) # height, width , color channel\n",
    "smallest_float16 = np.finfo(np.float16).tiny\n",
    "# normalize to 0-1\n",
    "X = X / 255.\n",
    "X = X.reshape((-1,) + image_shape)\n",
    "X = X.astype(smallest_float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"X.npy\", \"wb\") as file:\n",
    "    np.save(file, X)\n",
    "with open(\"y.npy\", \"wb\") as file:\n",
    "    np.save(file, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, min_delta=0.001, start_from_epoch=15, restore_best_weights=True)\n",
    "epochs = 200\n",
    "batch_size = 32\n",
    "dropout_rate = 0.4 # https://www.kaggle.com/code/rafjaa/dealing-with-very-small-datasets interessant bzgl oberfitting\n",
    "weight_decay_alpha = 0.01\n",
    "\n",
    "def create_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=image_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay_alpha)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay_alpha)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu', kernel_regularizer=regularizers.l2(weight_decay_alpha)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu', kernel_regularizer=regularizers.l2(weight_decay_alpha)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(weight_decay_alpha)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(weight_decay_alpha)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_optimizers(num_samples) -> dict:\n",
    "    s = 130 * num_samples // 32 # number of steps in 130 epochs (batch size = 32)\n",
    "    exp_decay_sgd = ExponentialDecay(0.01, s, 0.1)\n",
    "    exp_adam = ExponentialDecay(0.01, s, 0.95, staircase=True)\n",
    "\n",
    "    momentum = 0.99\n",
    "    sgd_exp = SGD(exp_decay_sgd, momentum=momentum)\n",
    "    adam_exp = Adam(exp_adam)\n",
    "\n",
    "    sgd = SGD(0.001, momentum=momentum)\n",
    "    adam = Adam(0.001)\n",
    "\n",
    "    return {\"sgd_exp\": sgd_exp, \"adam_exp\": adam_exp, \"sgd\": sgd, \"adam\": adam}\n",
    "\n",
    "histories_with_params = list()\n",
    "\n",
    "end_step = np.ceil(X.shape[0] / batch_size).astype(np.int32) * epochs\n",
    "\n",
    "pruning_params = {\n",
    "    # In this example, you start the model with 50% sparsity (50% zeros in weights) and end with 80% sparsity.\n",
    "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.50,\n",
    "                                                                final_sparsity=0.80,\n",
    "                                                                begin_step=0,\n",
    "                                                                end_step=end_step)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_model(model, X_train, y_train, worker=8):\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        workers=worker, # workers are number of cores\n",
    "        callbacks=[early_stopping, tfmot.sparsity.keras.UpdatePruningStep()],\n",
    "        validation_split=0.2,\n",
    "        verbose=1)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "23/23 [==============================] - 2s 61ms/step - loss: 11.4702 - accuracy: 0.3500 - val_loss: 99.8486 - val_accuracy: 0.0278\n",
      "Epoch 2/200\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 17.2586 - accuracy: 0.6458 - val_loss: 269.3952 - val_accuracy: 0.0167\n",
      "Epoch 3/200\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 26.2496 - accuracy: 0.6069 - val_loss: 105.5293 - val_accuracy: 0.0167\n",
      "Epoch 4/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 31.9442 - accuracy: 0.6125 - val_loss: 51.4174 - val_accuracy: 0.3444\n",
      "Epoch 5/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 31.9176 - accuracy: 0.6472 - val_loss: 39.2450 - val_accuracy: 0.0556\n",
      "Epoch 6/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 27.0985 - accuracy: 0.6347 - val_loss: 32.4499 - val_accuracy: 0.0056\n",
      "Epoch 7/200\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 19.7177 - accuracy: 0.6139 - val_loss: 25.0297 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 12.2412 - accuracy: 0.6458 - val_loss: 17.4543 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 6.4943 - accuracy: 0.6347 - val_loss: 13.8246 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 3.2013 - accuracy: 0.6333 - val_loss: 12.4602 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "23/23 [==============================] - 1s 51ms/step - loss: 2.2687 - accuracy: 0.6222 - val_loss: 12.3056 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 3.0695 - accuracy: 0.6222 - val_loss: 12.3657 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 5.0663 - accuracy: 0.6750 - val_loss: 12.6000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 6.7119 - accuracy: 0.6819 - val_loss: 13.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 7.3941 - accuracy: 0.6806 - val_loss: 12.6094 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 6.9056 - accuracy: 0.7208 - val_loss: 11.1111 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 5.5961 - accuracy: 0.7153 - val_loss: 9.7502 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 4.0320 - accuracy: 0.7306 - val_loss: 7.6927 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "23/23 [==============================] - 1s 52ms/step - loss: 2.6401 - accuracy: 0.7486 - val_loss: 6.9886 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 1.6783 - accuracy: 0.7417 - val_loss: 6.3011 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 1.3133 - accuracy: 0.7694 - val_loss: 6.5009 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 1.6169 - accuracy: 0.7542 - val_loss: 7.3988 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 2.4481 - accuracy: 0.7278 - val_loss: 7.8215 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 3.2779 - accuracy: 0.7417 - val_loss: 9.0089 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 3.7382 - accuracy: 0.7681 - val_loss: 9.0932 - val_accuracy: 0.0111\n",
      "Epoch 26/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 3.6697 - accuracy: 0.7778 - val_loss: 8.7849 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 3.2349 - accuracy: 0.7847 - val_loss: 8.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.6619 - accuracy: 0.7681 - val_loss: 7.8791 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.1809 - accuracy: 0.7875 - val_loss: 7.6345 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 1.8388 - accuracy: 0.7903 - val_loss: 7.0397 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 1.6999 - accuracy: 0.7889 - val_loss: 7.2778 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 1.6928 - accuracy: 0.7764 - val_loss: 7.1143 - val_accuracy: 0.0056\n",
      "Epoch 33/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 1.9346 - accuracy: 0.7861 - val_loss: 8.1974 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.2198 - accuracy: 0.7708 - val_loss: 8.2216 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.4677 - accuracy: 0.7708 - val_loss: 8.3811 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 2.5560 - accuracy: 0.7792 - val_loss: 7.9604 - val_accuracy: 0.0056\n",
      "Epoch 37/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.4571 - accuracy: 0.7847 - val_loss: 8.1441 - val_accuracy: 0.0111\n",
      "Epoch 38/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.3173 - accuracy: 0.7806 - val_loss: 8.7227 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 2.1659 - accuracy: 0.7819 - val_loss: 8.3064 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.0137 - accuracy: 0.7972 - val_loss: 8.1749 - val_accuracy: 0.0778\n",
      "Epoch 41/200\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 1.9780 - accuracy: 0.7806 - val_loss: 7.8791 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 1.9683 - accuracy: 0.7903 - val_loss: 7.7681 - val_accuracy: 0.0333\n",
      "Epoch 43/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 1.9671 - accuracy: 0.8000 - val_loss: 7.9678 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.0330 - accuracy: 0.7944 - val_loss: 8.8554 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 2.0941 - accuracy: 0.7958 - val_loss: 8.6927 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.1310 - accuracy: 0.7875 - val_loss: 8.1307 - val_accuracy: 0.0333\n",
      "Epoch 47/200\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 2.1791 - accuracy: 0.8014 - val_loss: 7.9050 - val_accuracy: 0.0611\n",
      "Epoch 48/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.2153 - accuracy: 0.7986 - val_loss: 8.9509 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 2.1860 - accuracy: 0.8014 - val_loss: 8.6137 - val_accuracy: 0.0111\n",
      "Epoch 50/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.1460 - accuracy: 0.8181 - val_loss: 6.7139 - val_accuracy: 0.3278\n",
      "Epoch 51/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.1476 - accuracy: 0.7931 - val_loss: 7.3281 - val_accuracy: 0.3000\n",
      "Epoch 52/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 2.1677 - accuracy: 0.7944 - val_loss: 7.1464 - val_accuracy: 0.2667\n",
      "Epoch 53/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.2209 - accuracy: 0.7806 - val_loss: 8.0660 - val_accuracy: 0.0056\n",
      "Epoch 54/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 2.2063 - accuracy: 0.7889 - val_loss: 7.3630 - val_accuracy: 0.0333\n",
      "Epoch 55/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.2003 - accuracy: 0.7931 - val_loss: 7.7318 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.1226 - accuracy: 0.7986 - val_loss: 6.9951 - val_accuracy: 0.0944\n",
      "Epoch 57/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.1204 - accuracy: 0.7931 - val_loss: 6.3756 - val_accuracy: 0.2111\n",
      "Epoch 58/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.0812 - accuracy: 0.8097 - val_loss: 6.5611 - val_accuracy: 0.2333\n",
      "Epoch 59/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.1120 - accuracy: 0.8028 - val_loss: 7.8931 - val_accuracy: 0.0167\n",
      "Epoch 60/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.0953 - accuracy: 0.8181 - val_loss: 7.6371 - val_accuracy: 0.1333\n",
      "Epoch 61/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.0923 - accuracy: 0.8042 - val_loss: 7.2359 - val_accuracy: 0.2167\n",
      "Epoch 62/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.0541 - accuracy: 0.8042 - val_loss: 6.9667 - val_accuracy: 0.0889\n",
      "Epoch 63/200\n",
      "23/23 [==============================] - 1s 53ms/step - loss: 2.0727 - accuracy: 0.8028 - val_loss: 6.3559 - val_accuracy: 0.2056\n",
      "Epoch 64/200\n",
      "23/23 [==============================] - 1s 55ms/step - loss: 2.1163 - accuracy: 0.7972 - val_loss: 7.2681 - val_accuracy: 0.0389\n",
      "Epoch 65/200\n",
      "23/23 [==============================] - 1s 54ms/step - loss: 2.0704 - accuracy: 0.7833 - val_loss: 7.8152 - val_accuracy: 0.0222\n",
      "Epoch 66/200\n",
      "23/23 [==============================] - 1s 56ms/step - loss: 2.0524 - accuracy: 0.7861 - val_loss: 8.1538 - val_accuracy: 0.0222\n",
      "Epoch 67/200\n",
      "23/23 [==============================] - 1s 59ms/step - loss: 1.9221 - accuracy: 0.8083 - val_loss: 7.6115 - val_accuracy: 0.0167\n",
      "Epoch 68/200\n",
      "23/23 [==============================] - 1s 57ms/step - loss: 1.8918 - accuracy: 0.7903 - val_loss: 8.4418 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "17/23 [=====================>........] - ETA: 0s - loss: 1.8170 - accuracy: 0.7868"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [10], line 20\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39moptimizer, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse_categorical_crossentropy\u001b[39m\u001b[38;5;124m\"\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     19\u001b[0m K\u001b[38;5;241m.\u001b[39mclear_session()\n\u001b[0;32m---> 20\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mfit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [8], line 2\u001b[0m, in \u001b[0;36mfit_model\u001b[0;34m(model, X_train, y_train, worker)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit_model\u001b[39m(model, X_train, y_train, worker\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m8\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# workers are number of cores\u001b[39;49;00m\n\u001b[1;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mearly_stopping\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtfmot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparsity\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeras\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mUpdatePruningStep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m history\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/engine/training.py:1650\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1642\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1643\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1644\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1648\u001b[0m ):\n\u001b[1;32m   1649\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1650\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1651\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1652\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:880\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    877\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 880\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    882\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    883\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:912\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    909\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    910\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    911\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 912\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    914\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    915\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    916\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:134\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    132\u001b[0m   (concrete_function,\n\u001b[1;32m    133\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1745\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1741\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1744\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1745\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1746\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1747\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m     args,\n\u001b[1;32m   1749\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1750\u001b[0m     executing_eagerly)\n\u001b[1;32m   1751\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:378\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    377\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 378\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    381\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    382\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    384\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    385\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    386\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    387\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    390\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    391\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "chunk_size = 1000\n",
    "y = np.load(\"y.npy\", mmap_mode=\"r+\")\n",
    "num_samples = len(y)\n",
    "del y\n",
    "gc.collect()\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "optimizers = create_optimizers(num_samples)\n",
    "for optimizer_name, optimizer in optimizers.items():\n",
    "    model = tfmot.sparsity.keras.prune_low_magnitude(model, **pruning_params)\n",
    "    for i in range(0, num_samples, chunk_size):\n",
    "        X = np.load(\"X.npy\", mmap_mode=\"r+\")\n",
    "        y = np.load(\"y.npy\", mmap_mode=\"r+\")\n",
    "        for train_indezes, test_indezes in kfold.split(X[i:i+chunk_size], y[i:i+chunk_size]):\n",
    "            X_train, y_train = tf.convert_to_tensor(X[train_indezes]), tf.convert_to_tensor(y[train_indezes])\n",
    "            X_test, y_test = tf.convert_to_tensor(X[train_indezes]), tf.convert_to_tensor(y[test_indezes])\n",
    "            model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "            K.clear_session()\n",
    "            history = fit_model(model, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training and validating the model using KFold\n",
    "history_with_param = {\"optimizer\": optimizer_name, \"history\": history}\n",
    "histories_with_params.append(history_with_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_epochs = len(history.history[\"accuracy\"])\n",
    "for history_with_param in histories_with_params:\n",
    "    K.clear_session()\n",
    "    model = load_model(f\"cnn_files/model_{history_with_param['optimizer']}.keras\")\n",
    "    test_score = round(model.evaluate(X_test, y_test)[1], 2)*100\n",
    "    gc.collect()\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(history_with_param[\"history\"].history[\"accuracy\"], label=\"train_data accuracy\")\n",
    "    plt.plot(history_with_param[\"history\"].history[\"val_accuracy\"], label=\"val_data accuracy\")\n",
    "    plt.scatter(number_of_epochs, test_score/100, label=\"test_data accuracy\", marker=\"x\", c=\"g\")\n",
    "    plt.title(f\"opt: {history_with_param['optimizer']} Test Score: {test_score}%\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(f\"./cnn_files/{history_with_param['optimizer']}.png\",dpi=600)\n",
    "    #plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
