{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main CNN model for bat call classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from typing import Callable\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "import math\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools_len as itertools\n",
    "from itertools_len import product\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory optimization, see https://github.com/tensorflow/tensorflow/issues/31312#issuecomment-813944860\n",
    "class ClearMemory(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        tf.keras.backend.clear_session()\n",
    "#        tf.reset_default_graph()\n",
    "        gc.collect()\n",
    "\n",
    "def reset_keras():\n",
    "    sess = tf.compat.v1.keras.backend.get_session()\n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "    sess.close()\n",
    "    sess = tf.compat.v1.keras.backend.get_session()\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    #config = tf.compat.v1.ConfigProto()\n",
    "    #config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    #config.gpu_options.visible_device_list = \"0\"\n",
    "    #tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to track execution time of certain code events\n",
    "class track_time:\n",
    "    def __init__(self):\n",
    "        self.events = []\n",
    "        self.add('Start')\n",
    "    def add(self, name: str) -> None:\n",
    "        if name == \"total\":\n",
    "            raise RuntimeError(\"Cant use the name 'total'.\")\n",
    "        self.events.append([name,time.time()])\n",
    "    def get_time(self): # calculate time between events and total\n",
    "        self.timed_events = {}\n",
    "        for (n, event) in enumerate(self.events):\n",
    "            elapsed_time = 0\n",
    "            if n+1 == len(self.events):\n",
    "                # last element\n",
    "                elapsed_time = time.time() - event[1]\n",
    "            else:\n",
    "                elapsed_time = self.events[n+1][1] - event[1]\n",
    "            self.timed_events[event[0]] = elapsed_time\n",
    "        self.timed_events['total'] = time.time() - self.events[0][1]\n",
    "        return self.timed_events\n",
    "    def __str__(self):\n",
    "        output = \"\"\n",
    "        if not hasattr(self,'timed_events'):\n",
    "            self.get_time()\n",
    "        output += (\"  Event tracked  |  Duration  \\n\")\n",
    "        output += (\"==============================\\n\")\n",
    "        for name,duration in self.timed_events.items():\n",
    "            output += (\" \"+name+\"\\t\\t\\t| \"+str(round(duration,3))+\"\\n\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer\n",
    "timer = track_time()\n",
    "timer.add(\"Read in data\")\n",
    "# load image data s and reshape \n",
    "data = pd.read_pickle('./data/images_df_numerical.pkl')\n",
    "# convert to numpy array\n",
    "X, y = data['data'], data['Species']\n",
    "classes = y.unique()\n",
    "image_size = X[0].size\n",
    "samples = X.size\n",
    "image_shape = (216,334,3) # height, width , channel\n",
    "# reshape every row to the image, swap rgbs and scale to 0-1\n",
    "X = [\n",
    "    cv2.cvtColor(row.reshape(image_shape), cv2.COLOR_BGR2RGB).astype('float32')/255. \n",
    "    for row in X]\n",
    "y = [row.astype('int32') for row in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 16:57:06.125918: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/marcel/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-12-20 16:57:06.125940: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-20 16:57:06.125959: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (marcel-laptop): /proc/driver/nvidia/version does not exist\n",
      "2023-12-20 16:57:06.131614: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 16:57:06.136586: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 794738304 exceeds 10% of free system memory.\n",
      "2023-12-20 16:57:07.229435: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 264912768 exceeds 10% of free system memory.\n",
      "2023-12-20 16:57:07.783017: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 265778496 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "timer.add(\"Split Train/Test\")\n",
    "# Cross Valiadation, wenn wir ein \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "# conver to tensor for memory optimization\n",
    "X_train = tf.convert_to_tensor(np.array(X_train))\n",
    "y_train = tf.convert_to_tensor(np.array(y_train))\n",
    "\n",
    "X_val = tf.convert_to_tensor(np.array(X_val))\n",
    "y_val = tf.convert_to_tensor(np.array(y_val))\n",
    "\n",
    "X_test = tf.convert_to_tensor(np.array(X_test))\n",
    "y_test = tf.convert_to_tensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "number_of_classes = classes.size\n",
    "pooling_size = (2, 2)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, min_delta=0.001, start_from_epoch=15, restore_best_weights=True)\n",
    "padding = \"same\"\n",
    "epochs = 1\n",
    "dropout_rate = 1 - 0.8 # ggf anpassen, wenn overfittet\n",
    "\n",
    "def create_model(conv_kernel_sizes: list, conv_filter_nums: list, number_of_neurons: list, optimizer=\"adam\", activation_function=\"relu\"):\n",
    "    f1 = F1Score(num_classes=number_of_classes, average=\"micro\")\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    # adding activaation function seperate for memory optimization, \n",
    "    #   see https://github.com/tensorflow/tensorflow/issues/46475#issuecomment-817191096 and \n",
    "    #       https://github.com/tensorflow/tensorflow/issues/46475#issuecomment-1288677907\n",
    "    \n",
    "    model.add(Conv2D(conv_filter_nums[0], conv_kernel_sizes[0],activation=activation_function,input_shape=image_shape,padding=padding))\n",
    "    #model.add(activation_function)\n",
    "    # MaxPool2D((2, 2), strides=(2, 2), dtype=\"mixed_float16\")(x)\n",
    "    model.add(MaxPool2D(pooling_size, strides=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(conv_filter_nums[1],conv_kernel_sizes[1],activation=activation_function, padding=padding))\n",
    "    #model.add(activation_function)\n",
    "    model.add(MaxPool2D(pooling_size, strides=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Classficiation\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(number_of_neurons[0], activation=activation_function))\n",
    "    #model.add(activation_function)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(number_of_neurons[1], activation=activation_function))\n",
    "    #model.add(activation_function)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(number_of_neurons[2], activation=activation_function))\n",
    "    #model.add(activation_function)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output-Layer\n",
    "    model.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\", f1]) #,run_eagerly=True) # eagerly for memory optimization, see https://github.com/tensorflow/tensorflow/issues/31312#issuecomment-821809246\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    #tf.compat.v1.reset_default_graph()\n",
    "    gc.collect()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 [==============================] - 19s 618ms/step - loss: 1.9879 - accuracy: 0.4542 - val_loss: 3.6025 - val_accuracy: 0.2026\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 18s 617ms/step - loss: 1.0465 - accuracy: 0.6841 - val_loss: 4.5072 - val_accuracy: 0.2026\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 18s 607ms/step - loss: 0.6358 - accuracy: 0.8039 - val_loss: 5.4335 - val_accuracy: 0.2026\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 18s 617ms/step - loss: 0.3623 - accuracy: 0.9139 - val_loss: 7.2307 - val_accuracy: 0.2026\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 21s 726ms/step - loss: 0.2510 - accuracy: 0.9292 - val_loss: 9.5384 - val_accuracy: 0.2026\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 22s 770ms/step - loss: 0.1552 - accuracy: 0.9542 - val_loss: 8.2748 - val_accuracy: 0.2026\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 24s 833ms/step - loss: 0.0880 - accuracy: 0.9837 - val_loss: 9.9813 - val_accuracy: 0.2026\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 24s 813ms/step - loss: 0.1153 - accuracy: 0.9749 - val_loss: 6.6516 - val_accuracy: 0.2026\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 23s 810ms/step - loss: 0.0944 - accuracy: 0.9782 - val_loss: 7.1877 - val_accuracy: 0.2026\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 23s 790ms/step - loss: 0.0753 - accuracy: 0.9880 - val_loss: 7.0489 - val_accuracy: 0.2026\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 23s 788ms/step - loss: 0.0714 - accuracy: 0.9858 - val_loss: 6.4566 - val_accuracy: 0.2026\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - ETA: 0s - loss: 0.0743 - accuracy: 0.9804"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.experimental import Adagrad\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "number_of_classes = classes.size\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, min_delta=0.001, start_from_epoch=15, restore_best_weights=True)\n",
    "epochs = 200\n",
    "\n",
    "def kaggle_model(optimizer):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=image_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "s = 130 * len(X_train) // 32 # number of steps in 130 epochs (batch size = 32)\n",
    "exp_decay_sgd_adagrad = ExponentialDecay(0.01, s, 0.1)\n",
    "exp_adam = ExponentialDecay(0.1, s, 0.95, staircase=True)\n",
    "\n",
    "\n",
    "sgd = SGD(exp_decay_sgd_adagrad)\n",
    "adam = Adam(exp_adam)\n",
    "adagrad = Adagrad(exp_decay_sgd_adagrad)\n",
    "\n",
    "optimizers = [sgd, adam, adagrad]\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    model = kaggle_model(optimizer)\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        workers=8, # workers are number of cores\n",
    "        callbacks=early_stopping,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307,)\n",
      "Trying out 300 different combination.\n",
      "Now training model with bs=8, ls=0.01, kn=(3, 3)x(3, 3), ft=32x32, nn=256x128x64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 16:12:09.389877: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/115 [>.............................] - ETA: 5s - loss: 29.6231 - accuracy: 0.2500 - f1_score: 0.2698   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0133s vs `on_train_batch_end` time: 0.0278s). Check your callbacks.\n",
      " 27/115 [======>.......................] - ETA: 4s - loss: 23.5991 - accuracy: 0.3148 - f1_score: 0.2694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "\n",
    "batch_sizes = [8, 16, 32, 64, 128]\n",
    "learning_rates = [0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "conv_kernel_sizes = [[(3,3), (3, 3)],[(7,7), (3, 3)],[(11,11), (3, 3)]] # schauen, ob ggf. wir mehr layer benutzen\n",
    "conv_filter_nums = [[32,32],[32, 64],[64,64],[64,32]]\n",
    "number_of_neurons = [[256, 128, 64]]\n",
    "histories_with_params = list()\n",
    "\n",
    "test_list = product(batch_sizes, learning_rates, conv_kernel_sizes, conv_filter_nums, number_of_neurons)\n",
    "print(f\"Trying out {len(test_list)} different combination.\")\n",
    "# do again cause list\n",
    "test_list = product(batch_sizes, learning_rates, conv_kernel_sizes, conv_filter_nums, number_of_neurons)\n",
    "\n",
    "for batch_size, learning_rate, conv_kernel_size, conv_filter_num, number_of_neuron in test_list:\n",
    "    print(f\"Now training model with bs={batch_size}, ls={learning_rate}, kn={conv_kernel_size[0]}x{conv_kernel_size[1]}, ft={conv_filter_num[0]}x{conv_filter_num[1]}, nn={number_of_neuron[0]}x{number_of_neuron[1]}x{number_of_neuron[2]}\")\n",
    "    model = create_model(conv_kernel_size, conv_filter_num,number_of_neuron)\n",
    "    #model.summary()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        #workers=8, # workers are number of cores\n",
    "        callbacks=[early_stopping,ClearMemory()],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1)\n",
    "    \n",
    "    #parameters = {\n",
    "    #    \"bs\": batch_size, \n",
    "    #    \"lr\": learning_rate,\n",
    "    #    \"kn\": conv_kernel_size,\n",
    "    #    \"ft\": conv_filter_num,\n",
    "    #    \"nn\": number_of_neuron,\n",
    "    #    \"ts\": round(model.evaluate(X_test, y_test)[1], 2)*100\n",
    "    #}\n",
    "    \n",
    "    #history_with_param = {\"history\": history, \"parameters\": parameters}\n",
    "    #\n",
    "    #histories_with_params.append(history_with_param)\n",
    "    # too clear cache?\n",
    "    model.save(f'./t/a.keras',overwrite=True)\n",
    "\n",
    "    #print(f\"Epochs: {len(history.history['accuracy'])}\")\n",
    "    #print(f\"Test Score: {round(model.evaluate(X_test, y_test)[1], 2)}%\")\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    #reset_keras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#number_of_epochs = len(history.history[\"accuracy\"])\n",
    "\n",
    "#for history_with_param in histories_with_params:\n",
    "    #model = load_model(f\"./cnn_files/cnn_bs{\n",
    "    #    history_with_param['parameters']['bs']\n",
    "    #    }_ls{\n",
    "    #    history_with_param['parameters']['lr']\n",
    "    #    }_kn{\n",
    "    #    history_with_param['parameters']['kn'][0]\n",
    "    #    }x{\n",
    "    #    history_with_param['parameters']['kn'][1]\n",
    "    #    }_ft{\n",
    "    #    history_with_param['parameters']['ft'][0]\n",
    "    #    }x{\n",
    "    #    history_with_param['parameters']['ft'][1]\n",
    "    #    }_nn{\n",
    "    #    history_with_param['parameters']['nn'][0]\n",
    "    #    }x{\n",
    "    #    history_with_param['parameters']['nn'][1]\n",
    "    #    }x{\n",
    "    #    history_with_param['parameters']['nn'][2]\n",
    "    #    }.keras\")\n",
    "    \n",
    "#    plt.plot(history_with_param[\"history\"].history[\"val_accuracy\"], label=\"val_data accuracy\")\n",
    "#    plt.plot(history_with_param[\"history\"].history[\"accuracy\"], label=\"train_data accuracy\")\n",
    "#    \n",
    "#    plt.scatter(number_of_epochs, model.evaluate(X_test, y_test)[1], label=\"test_data accuracy\", marker=\"x\", c=\"g\")\n",
    "#    plt.title(f\"bs{\n",
    "#        history_with_param['parameters']['bs']\n",
    "##        } ls{\n",
    "#        history_with_param['parameters']['lr']\n",
    "#        }\\nkn{\n",
    "#        history_with_param['parameters']['kn'][0]\n",
    "#        }x{\n",
    "#        history_with_param['parameters']['kn'][1]\n",
    "#        } ft{\n",
    "#        history_with_param['parameters']['ft'][0]\n",
    "#        }x{\n",
    " #       history_with_param['parameters']['ft'][1]\n",
    " ##       }\\nnn{\n",
    " #       history_with_param['parameters']['nn'][0]\n",
    " #       }x{\n",
    "  #      history_with_param['parameters']['nn'][1]\n",
    "#        }x{\n",
    "#        history_with_param['parameters']['nn'][2]\n",
    "#        }\\nts{\n",
    "#        history_with_param['parameters']['ts']\n",
    "#        }\")\n",
    "#    plt.xlabel(\"Epochs\")\n",
    "#    plt.ylabel(\"Accuracy\")\n",
    "#    plt.legend(loc=\"lower right\")\n",
    "#    plt.savefig(f\"./cnn_files/cnn_bs{\n",
    "#        history_with_param['parameters']['bs']\n",
    "#        }_ls{\n",
    "#        history_with_param['parameters']['lr']\n",
    "#        }_kn{\n",
    "#        history_with_param['parameters']['kn'][0]\n",
    "#        }x{\n",
    "##        history_with_param['parameters']['kn'][1]\n",
    "#        }_ft{\n",
    "##        history_with_param['parameters']['ft'][0]\n",
    "#        }x{\n",
    "#        history_with_param['parameters']['ft'][1]\n",
    "#        }_nn{\n",
    "#        history_with_param['parameters']['nn'][0]\n",
    "#        }x{\n",
    " #       history_with_param['parameters']['nn'][1]\n",
    " #       }x{\n",
    "#       history_with_param['parameters']['nn'][2]\n",
    "#        }.keras\",dpi=200)\n",
    "#    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints n=|base_group| figures with subplots, based on the other paramters\n",
    "#def print_results(base_group: (str,list), histories_all: list, number_of_epochs: int) -> None:\n",
    "#    # for everx value of base group create figure, and than create subplots based on how many paramters there are\n",
    "#    for val in base_group[1]:\n",
    "#        # get all histires with said value\n",
    "#        histories = [his for his in histories_all if his['parameters'][base_group[0]]==val]    \n",
    "#        # Compute Rows required\n",
    "#        total = len(base_group[1])\n",
    "#        cols = int((total)**0.5)\n",
    "#        rows = total // cols\n",
    "#        if total % cols != 0:\n",
    "#            rows += 1\n",
    "#        pos = range(1,total+1)\n",
    "#        \n",
    "#        # plot\n",
    "#        fig = plt.figure(figsize=(15,10))\n",
    "#        for i in range(0,len(histories)):\n",
    "#            # load model\n",
    "#            model = load_model(f\"./cnn_files/cnn_bs{histories[i]['parameters']['bs']}_ls{histories[i]['parameters']['lr']}.keras\")\n",
    "#            # get test score\n",
    "#            test_score = round(model.evaluate(X_test, y_test)[1], 2)*100\n",
    "#            # make a new subplot for every history\n",
    "#            ax = fig.add_subplot(rows,cols,pos[i])\n",
    "#            ax.set_ylim([0,1])\n",
    "#            ax.set_xlim([0,number_of_epochs])\n",
    "#            ax.plot(histories[i][\"history\"].history[\"val_accuracy\"], label=\"val_data accuracy\")\n",
    "#            ax.plot(histories[i][\"history\"].history[\"accuracy\"], label=\"train_data accuracy\")\n",
    "#            ax.set_title(f\"{base_group[0]}: {histories[i]['parameters'][base_group[0]]} lr: {histories[i]['parameters']['lr']}, Test Score: {test_score}%\")\n",
    "#            ax.set_xlabel(\"Epochs\")\n",
    "#            ax.set_ylabel(\"Accuracy\")\n",
    "#            ax.legend(loc=\"lower right\")\n",
    "#        plt.savefig(f\"t/{val}_a.png\")        \n",
    "#        plt.show()\n",
    "#        plt.close()\n",
    "#\n",
    "#print_results(('bs',batch_sizes),histories_with_params,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.backend.clear_session()\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get memory usage\n",
    "\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted_vars = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_vars_in_gb = [(var, size / (1024 ** 3)) for var, size in sorted_vars]\n",
    "sorted_vars_in_gb\n",
    "total_memory = sum(size for _, size in sorted_vars)\n",
    "total_memory_in_gb = total_memory / (1024 ** 3)\n",
    "total_memory_in_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
