{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main CNN model for bat call classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools_len as itertools\n",
    "from itertools_len import product\n",
    "import gc\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load image data s and reshape \n",
    "data = pd.read_pickle('./data/images_df_numerical.pkl')\n",
    "# convert to numpy array\n",
    "X, y = data['data'], data['Species']\n",
    "classes = y.unique()\n",
    "image_size = X[0].size\n",
    "samples = X.size\n",
    "image_shape = (216,334,3) # height, width , channel\n",
    "# reshape every row to the image, swap rgbs and scale to 0-1\n",
    "X = np.array([\n",
    "    cv2.cvtColor(row.reshape(image_shape), cv2.COLOR_BGR2RGB).astype('float32')/255. \n",
    "    for row in X])\n",
    "y = np.array([row.astype('int32') for row in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=10, shuffle=True)\n",
    "\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "\n",
    "# If using TensorFlow, this will make GPU ops as deterministic as possible,\n",
    "# but it will affect the overall performance, so be mindful of that.\n",
    "tf.config.experimental.enable_op_determinism()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "number_of_classes = classes.size\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, min_delta=0.001, start_from_epoch=15, restore_best_weights=True)\n",
    "epochs = 200\n",
    "dropout_rate = 0.4\n",
    "\n",
    "def kaggle_model(optimizer):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=image_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "def create_optimizers(X_train) -> dict:\n",
    "    s = 130 * len(X_train) // 32 # number of steps in 130 epochs (batch size = 32)\n",
    "    exp_decay_sgd_adagrad = ExponentialDecay(0.01, s, 0.1)\n",
    "    exp_adam = ExponentialDecay(0.1, s, 0.95, staircase=True)\n",
    "\n",
    "    momentum = 0.99\n",
    "    sgd_exp = SGD(exp_decay_sgd_adagrad, momentum=momentum)\n",
    "    adam_exp = Adam(exp_adam)\n",
    "\n",
    "    sgd = SGD(0.001, momentum=momentum)\n",
    "    adam = Adam(0.001)\n",
    "\n",
    "    return {\"sgd_exp\": sgd_exp, \"adam_exp\": adam_exp, \"sgd\": sgd, \"adam\": adam}\n",
    "\n",
    "histories_with_params = list()\n",
    "\n",
    "# Training and validating the model using KFold\n",
    "for train_indezes, test_indezes in kfold.split(X, y):\n",
    "    X_train, y_train = X[train_indezes], y[test_indezes]\n",
    "    X_test, y_test = X[train_indezes], y[test_indezes]\n",
    "\n",
    "    optimizers = create_optimizers(X_train)\n",
    "\n",
    "    for optimizer_name, optimizer in optimizers.items():\n",
    "        model = kaggle_model(optimizer)\n",
    "        history = model.fit(\n",
    "            X_train,\n",
    "            y_train,\n",
    "            epochs=epochs,\n",
    "            batch_size=32,\n",
    "            workers=1, # workers are number of cores\n",
    "            callbacks=early_stopping,\n",
    "            validation_split=0.2,\n",
    "            verbose=1)\n",
    "        model.save(\"cnn_files/model.h5\", overwrite=True)\n",
    "        history_with_param = {\"optimizer\": optimizer_name, \"history\": history}\n",
    "        histories_with_params.append(history_with_param)\n",
    "\n",
    "number_of_epochs = len(history.history[\"accuracy\"])\n",
    "for history_with_param in histories_with_params:\n",
    "    plt.plot(history_with_param[\"history\"].history[\"accuracy\"], label=\"train_data accuracy\")\n",
    "    plt.plot(history_with_param[\"history\"].history[\"val_accuracy\"], label=\"val_data accuracy\")\n",
    "    plt.scatter(number_of_epochs, model.evaluate(X_test, y_test)[1], label=\"test_data accuracy\", marker=\"x\", c=\"g\")\n",
    "    plt.title(f\"opt: {history_with_param['optimizer']} Test Score: {round(model.evaluate(X_test, y_test)[1], 2)}%\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(f\"./cnn_files/{history_with_param['optimizer']}.png\",dpi=600)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
