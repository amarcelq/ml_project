{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main CNN model for bat call classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.11.0\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from typing import Callable\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, Flatten, MaxPool2D, Dropout\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow_addons.metrics import F1Score\n",
    "import math\n",
    "import pickle\n",
    "import cv2\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import itertools_len as itertools\n",
    "from itertools_len import product\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# memory optimization, see https://github.com/tensorflow/tensorflow/issues/31312#issuecomment-813944860\n",
    "class ClearMemory(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        tf.keras.backend.clear_session()\n",
    "#        tf.reset_default_graph()\n",
    "        gc.collect()\n",
    "\n",
    "def reset_keras():\n",
    "    sess = tf.compat.v1.keras.backend.get_session()\n",
    "    tf.compat.v1.keras.backend.clear_session()\n",
    "    sess.close()\n",
    "    sess = tf.compat.v1.keras.backend.get_session()\n",
    "\n",
    "    print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    #config = tf.compat.v1.ConfigProto()\n",
    "    #config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    #config.gpu_options.visible_device_list = \"0\"\n",
    "    #tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to track execution time of certain code events\n",
    "class track_time:\n",
    "    def __init__(self):\n",
    "        self.events = []\n",
    "        self.add('Start')\n",
    "    def add(self, name: str) -> None:\n",
    "        if name == \"total\":\n",
    "            raise RuntimeError(\"Cant use the name 'total'.\")\n",
    "        self.events.append([name,time.time()])\n",
    "    def get_time(self): # calculate time between events and total\n",
    "        self.timed_events = {}\n",
    "        for (n, event) in enumerate(self.events):\n",
    "            elapsed_time = 0\n",
    "            if n+1 == len(self.events):\n",
    "                # last element\n",
    "                elapsed_time = time.time() - event[1]\n",
    "            else:\n",
    "                elapsed_time = self.events[n+1][1] - event[1]\n",
    "            self.timed_events[event[0]] = elapsed_time\n",
    "        self.timed_events['total'] = time.time() - self.events[0][1]\n",
    "        return self.timed_events\n",
    "    def __str__(self):\n",
    "        output = \"\"\n",
    "        if not hasattr(self,'timed_events'):\n",
    "            self.get_time()\n",
    "        output += (\"  Event tracked  |  Duration  \\n\")\n",
    "        output += (\"==============================\\n\")\n",
    "        for name,duration in self.timed_events.items():\n",
    "            output += (\" \"+name+\"\\t\\t\\t| \"+str(round(duration,3))+\"\\n\")\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# timer\n",
    "timer = track_time()\n",
    "timer.add(\"Read in data\")\n",
    "# load image data s and reshape \n",
    "data = pd.read_pickle('./data/images_df_numerical.pkl')\n",
    "# convert to numpy array\n",
    "X, y = data['data'], data['Species']\n",
    "classes = y.unique()\n",
    "image_size = X[0].size\n",
    "samples = X.size\n",
    "image_shape = (216,334,3) # height, width , channel\n",
    "# reshape every row to the image, swap rgbs and scale to 0-1\n",
    "X = [\n",
    "    cv2.cvtColor(row.reshape(image_shape), cv2.COLOR_BGR2RGB).astype('float32')/255. \n",
    "    for row in X]\n",
    "y = [row.astype('int32') for row in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 17:49:01.987032: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/marcel/.local/lib/python3.10/site-packages/cv2/../../lib64:\n",
      "2023-12-20 17:49:01.987372: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-12-20 17:49:01.987409: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (marcel-laptop): /proc/driver/nvidia/version does not exist\n",
      "2023-12-20 17:49:01.988768: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-20 17:49:01.992339: W tensorflow/tsl/framework/cpu_allocator_impl.cc:82] Allocation of 794738304 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "timer.add(\"Split Train/Test\")\n",
    "# Cross Valiadation, wenn wir ein \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1) \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
    "\n",
    "# conver to tensor for memory optimization\n",
    "X_train = tf.convert_to_tensor(np.array(X_train))\n",
    "y_train = tf.convert_to_tensor(np.array(y_train))\n",
    "\n",
    "X_val = tf.convert_to_tensor(np.array(X_val))\n",
    "y_val = tf.convert_to_tensor(np.array(y_val))\n",
    "\n",
    "X_test = tf.convert_to_tensor(np.array(X_test))\n",
    "y_test = tf.convert_to_tensor(np.array(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "number_of_classes = classes.size\n",
    "pooling_size = (2, 2)\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, min_delta=0.001, start_from_epoch=15, restore_best_weights=True)\n",
    "padding = \"same\"\n",
    "epochs = 1\n",
    "dropout_rate = 1 - 0.8 # ggf anpassen, wenn overfittet\n",
    "\n",
    "def create_model(conv_kernel_sizes: list, conv_filter_nums: list, number_of_neurons: list, optimizer=\"adam\", activation_function=\"relu\"):\n",
    "    f1 = F1Score(num_classes=number_of_classes, average=\"micro\")\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    # adding activaation function seperate for memory optimization, \n",
    "    #   see https://github.com/tensorflow/tensorflow/issues/46475#issuecomment-817191096 and \n",
    "    #       https://github.com/tensorflow/tensorflow/issues/46475#issuecomment-1288677907\n",
    "    \n",
    "    model.add(Conv2D(conv_filter_nums[0], conv_kernel_sizes[0],activation=activation_function,input_shape=image_shape,padding=padding))\n",
    "    #model.add(activation_function)\n",
    "    # MaxPool2D((2, 2), strides=(2, 2), dtype=\"mixed_float16\")(x)\n",
    "    model.add(MaxPool2D(pooling_size, strides=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Conv2D(conv_filter_nums[1],conv_kernel_sizes[1],activation=activation_function, padding=padding))\n",
    "    #model.add(activation_function)\n",
    "    model.add(MaxPool2D(pooling_size, strides=(2, 2)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Classficiation\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(number_of_neurons[0], activation=activation_function))\n",
    "    #model.add(activation_function)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(number_of_neurons[1], activation=activation_function))\n",
    "    #model.add(activation_function)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    model.add(Dense(number_of_neurons[2], activation=activation_function))\n",
    "    #model.add(activation_function)\n",
    "    model.add(Dropout(dropout_rate))\n",
    "\n",
    "    # Output-Layer\n",
    "    model.add(Dense(number_of_classes, activation=\"softmax\"))\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\", f1]) #,run_eagerly=True) # eagerly for memory optimization, see https://github.com/tensorflow/tensorflow/issues/31312#issuecomment-821809246\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    #tf.compat.v1.reset_default_graph()\n",
    "    gc.collect()\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "29/29 [==============================] - 23s 747ms/step - loss: 1.7842 - accuracy: 0.5229 - val_loss: 27.1903 - val_accuracy: 0.4346\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 21s 733ms/step - loss: 1.2664 - accuracy: 0.6808 - val_loss: 47.2023 - val_accuracy: 0.4967\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 21s 735ms/step - loss: 1.3107 - accuracy: 0.7026 - val_loss: 49.8692 - val_accuracy: 0.4444\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 1.3217 - accuracy: 0.7440 - val_loss: 18.4813 - val_accuracy: 0.4804\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 1.1898 - accuracy: 0.7146 - val_loss: 5.6584 - val_accuracy: 0.6961\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 21s 735ms/step - loss: 1.2490 - accuracy: 0.7495 - val_loss: 2.9968 - val_accuracy: 0.6863\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 1.1728 - accuracy: 0.7800 - val_loss: 3.7104 - val_accuracy: 0.5588\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 22s 744ms/step - loss: 0.9608 - accuracy: 0.7702 - val_loss: 5.6542 - val_accuracy: 0.5294\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 22s 744ms/step - loss: 0.8955 - accuracy: 0.8159 - val_loss: 3.6137 - val_accuracy: 0.5817\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 21s 741ms/step - loss: 0.8094 - accuracy: 0.8224 - val_loss: 1.7348 - val_accuracy: 0.6928\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 21s 741ms/step - loss: 0.7035 - accuracy: 0.7974 - val_loss: 1.8313 - val_accuracy: 0.6176\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 21s 738ms/step - loss: 0.6851 - accuracy: 0.8159 - val_loss: 1.5051 - val_accuracy: 0.6732\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 21s 742ms/step - loss: 0.5607 - accuracy: 0.8257 - val_loss: 1.0301 - val_accuracy: 0.7582\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 21s 739ms/step - loss: 0.5344 - accuracy: 0.8442 - val_loss: 1.9213 - val_accuracy: 0.5882\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 0.4573 - accuracy: 0.8431 - val_loss: 1.3322 - val_accuracy: 0.7451\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 21s 742ms/step - loss: 0.4477 - accuracy: 0.8769 - val_loss: 1.3789 - val_accuracy: 0.6373\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 21s 738ms/step - loss: 0.3811 - accuracy: 0.8834 - val_loss: 1.3950 - val_accuracy: 0.7157\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 22s 744ms/step - loss: 0.3969 - accuracy: 0.8932 - val_loss: 1.5264 - val_accuracy: 0.6373\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 22s 746ms/step - loss: 0.3822 - accuracy: 0.8791 - val_loss: 1.1035 - val_accuracy: 0.7680\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 0.3816 - accuracy: 0.8845 - val_loss: 1.6403 - val_accuracy: 0.7059\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 22s 742ms/step - loss: 0.3529 - accuracy: 0.8922 - val_loss: 1.4071 - val_accuracy: 0.6503\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 21s 741ms/step - loss: 0.3328 - accuracy: 0.8965 - val_loss: 0.8897 - val_accuracy: 0.7778\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 22s 746ms/step - loss: 0.2883 - accuracy: 0.8998 - val_loss: 1.1104 - val_accuracy: 0.7647\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 0.2938 - accuracy: 0.8976 - val_loss: 1.0636 - val_accuracy: 0.7582\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 22s 746ms/step - loss: 0.2350 - accuracy: 0.9237 - val_loss: 1.0475 - val_accuracy: 0.7680\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 21s 741ms/step - loss: 0.2643 - accuracy: 0.9096 - val_loss: 1.2317 - val_accuracy: 0.7647\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 21s 737ms/step - loss: 0.2750 - accuracy: 0.9107 - val_loss: 1.3470 - val_accuracy: 0.7157\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 22s 748ms/step - loss: 0.2759 - accuracy: 0.9107 - val_loss: 1.5580 - val_accuracy: 0.7353\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 22s 747ms/step - loss: 0.2992 - accuracy: 0.9041 - val_loss: 1.2086 - val_accuracy: 0.7418\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 22s 747ms/step - loss: 0.2415 - accuracy: 0.9205 - val_loss: 0.8693 - val_accuracy: 0.7418\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 22s 747ms/step - loss: 0.2824 - accuracy: 0.9161 - val_loss: 1.0982 - val_accuracy: 0.7353\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 22s 742ms/step - loss: 0.2168 - accuracy: 0.9270 - val_loss: 1.2206 - val_accuracy: 0.7386\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 22s 744ms/step - loss: 0.2431 - accuracy: 0.9172 - val_loss: 0.9427 - val_accuracy: 0.8105\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 21s 741ms/step - loss: 0.2281 - accuracy: 0.9237 - val_loss: 1.0169 - val_accuracy: 0.7484\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 22s 750ms/step - loss: 0.2155 - accuracy: 0.9368 - val_loss: 1.1313 - val_accuracy: 0.7320\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 21s 735ms/step - loss: 0.2397 - accuracy: 0.9336 - val_loss: 0.8683 - val_accuracy: 0.7680\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 21s 740ms/step - loss: 0.1676 - accuracy: 0.9423 - val_loss: 0.8824 - val_accuracy: 0.7876\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 21s 741ms/step - loss: 0.1594 - accuracy: 0.9434 - val_loss: 0.9583 - val_accuracy: 0.7745\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 0.1682 - accuracy: 0.9412 - val_loss: 1.0842 - val_accuracy: 0.7549\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 0.1374 - accuracy: 0.9532 - val_loss: 1.3623 - val_accuracy: 0.7157\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 22s 748ms/step - loss: 0.1567 - accuracy: 0.9444 - val_loss: 1.4329 - val_accuracy: 0.7222\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 22s 750ms/step - loss: 0.1636 - accuracy: 0.9379 - val_loss: 1.2229 - val_accuracy: 0.7222\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 22s 746ms/step - loss: 0.1391 - accuracy: 0.9553 - val_loss: 1.0204 - val_accuracy: 0.7288\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 22s 748ms/step - loss: 0.1377 - accuracy: 0.9455 - val_loss: 0.9023 - val_accuracy: 0.7647\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 22s 748ms/step - loss: 0.1223 - accuracy: 0.9619 - val_loss: 0.8051 - val_accuracy: 0.7876\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 22s 750ms/step - loss: 0.1119 - accuracy: 0.9564 - val_loss: 0.8259 - val_accuracy: 0.7908\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 22s 749ms/step - loss: 0.1161 - accuracy: 0.9564 - val_loss: 0.9854 - val_accuracy: 0.7418\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 22s 752ms/step - loss: 0.1152 - accuracy: 0.9532 - val_loss: 1.0804 - val_accuracy: 0.7451\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 22s 749ms/step - loss: 0.1163 - accuracy: 0.9597 - val_loss: 1.1085 - val_accuracy: 0.7647\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 22s 747ms/step - loss: 0.0924 - accuracy: 0.9717 - val_loss: 1.0946 - val_accuracy: 0.7680\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 22s 748ms/step - loss: 0.1042 - accuracy: 0.9641 - val_loss: 1.0023 - val_accuracy: 0.7843\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 22s 749ms/step - loss: 0.0993 - accuracy: 0.9673 - val_loss: 0.9749 - val_accuracy: 0.7843\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 22s 746ms/step - loss: 0.0948 - accuracy: 0.9651 - val_loss: 1.1140 - val_accuracy: 0.7680\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 22s 752ms/step - loss: 0.1027 - accuracy: 0.9706 - val_loss: 1.1928 - val_accuracy: 0.7745\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 0.0851 - accuracy: 0.9771 - val_loss: 1.2198 - val_accuracy: 0.7451\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 21s 741ms/step - loss: 0.0741 - accuracy: 0.9728 - val_loss: 1.1980 - val_accuracy: 0.7386\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 22s 744ms/step - loss: 0.0793 - accuracy: 0.9717 - val_loss: 1.1149 - val_accuracy: 0.7418\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 22s 744ms/step - loss: 0.0635 - accuracy: 0.9771 - val_loss: 0.9863 - val_accuracy: 0.7582\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 0.0771 - accuracy: 0.9662 - val_loss: 0.9396 - val_accuracy: 0.7745\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 22s 750ms/step - loss: 0.0860 - accuracy: 0.9749 - val_loss: 0.8719 - val_accuracy: 0.7908\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 22s 745ms/step - loss: 0.0880 - accuracy: 0.9717 - val_loss: 0.8233 - val_accuracy: 0.8072\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 22s 754ms/step - loss: 0.0800 - accuracy: 0.9760 - val_loss: 0.8537 - val_accuracy: 0.8007\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 22s 743ms/step - loss: 0.0604 - accuracy: 0.9804 - val_loss: 1.0112 - val_accuracy: 0.7974\n",
      "Epoch 1/200\n",
      "29/29 [==============================] - 25s 800ms/step - loss: 4.5313 - accuracy: 0.4423 - val_loss: 63.5032 - val_accuracy: 0.4641\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 23s 795ms/step - loss: 2.4895 - accuracy: 0.5479 - val_loss: 20.6817 - val_accuracy: 0.0654\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 23s 797ms/step - loss: 1.9624 - accuracy: 0.5381 - val_loss: 9.3400 - val_accuracy: 0.2157\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 23s 785ms/step - loss: 1.7334 - accuracy: 0.5784 - val_loss: 2.0125 - val_accuracy: 0.6438\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 23s 780ms/step - loss: 1.4110 - accuracy: 0.6580 - val_loss: 1.6392 - val_accuracy: 0.5294\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 23s 782ms/step - loss: 1.1884 - accuracy: 0.6808 - val_loss: 1.2296 - val_accuracy: 0.6176\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 23s 786ms/step - loss: 1.0335 - accuracy: 0.7124 - val_loss: 2.0174 - val_accuracy: 0.2778\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 23s 780ms/step - loss: 1.1049 - accuracy: 0.6993 - val_loss: 1.2727 - val_accuracy: 0.7222\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 23s 785ms/step - loss: 1.0396 - accuracy: 0.7211 - val_loss: 1.6952 - val_accuracy: 0.6307\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 1.0730 - accuracy: 0.7113 - val_loss: 2.5580 - val_accuracy: 0.4739\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 23s 800ms/step - loss: 1.0302 - accuracy: 0.7092 - val_loss: 1.9844 - val_accuracy: 0.5229\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 23s 796ms/step - loss: 0.9135 - accuracy: 0.7473 - val_loss: 1.5931 - val_accuracy: 0.7222\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 23s 796ms/step - loss: 0.8828 - accuracy: 0.7418 - val_loss: 4.0080 - val_accuracy: 0.3987\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 23s 805ms/step - loss: 0.7476 - accuracy: 0.7767 - val_loss: 2.1972 - val_accuracy: 0.5065\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 23s 790ms/step - loss: 0.8442 - accuracy: 0.7636 - val_loss: 14.2016 - val_accuracy: 0.1373\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 23s 796ms/step - loss: 0.7949 - accuracy: 0.7854 - val_loss: 11.1455 - val_accuracy: 0.2941\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 23s 791ms/step - loss: 0.8145 - accuracy: 0.7810 - val_loss: 27.8875 - val_accuracy: 0.2026\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 23s 790ms/step - loss: 0.7559 - accuracy: 0.7887 - val_loss: 36.9905 - val_accuracy: 0.2092\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 23s 797ms/step - loss: 0.6950 - accuracy: 0.7810 - val_loss: 20.8200 - val_accuracy: 0.0556\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 0.7384 - accuracy: 0.8017 - val_loss: 18.4418 - val_accuracy: 0.0033\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 0.7084 - accuracy: 0.8214 - val_loss: 13.2149 - val_accuracy: 0.0752\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 23s 798ms/step - loss: 0.7891 - accuracy: 0.7821 - val_loss: 67.1156 - val_accuracy: 0.2026\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 23s 793ms/step - loss: 0.9614 - accuracy: 0.7527 - val_loss: 8.8684 - val_accuracy: 0.3268\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 23s 794ms/step - loss: 1.0026 - accuracy: 0.7810 - val_loss: 26.7716 - val_accuracy: 0.2549\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 23s 785ms/step - loss: 1.6150 - accuracy: 0.6983 - val_loss: 29.8514 - val_accuracy: 0.4510\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 23s 794ms/step - loss: 1.2989 - accuracy: 0.7451 - val_loss: 39.0979 - val_accuracy: 0.6503\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 23s 786ms/step - loss: 1.6823 - accuracy: 0.7113 - val_loss: 71.3148 - val_accuracy: 0.3987\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 23s 787ms/step - loss: 1.7937 - accuracy: 0.7004 - val_loss: 9.9358 - val_accuracy: 0.6405\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 23s 789ms/step - loss: 2.0853 - accuracy: 0.6383 - val_loss: 8.7927 - val_accuracy: 0.6471\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 23s 795ms/step - loss: 2.3981 - accuracy: 0.6688 - val_loss: 6.2962 - val_accuracy: 0.3170\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 23s 793ms/step - loss: 2.0872 - accuracy: 0.6830 - val_loss: 4.3011 - val_accuracy: 0.5163\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 23s 793ms/step - loss: 1.5568 - accuracy: 0.7146 - val_loss: 4.3823 - val_accuracy: 0.2843\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 23s 797ms/step - loss: 1.6010 - accuracy: 0.7146 - val_loss: 5.6659 - val_accuracy: 0.2876\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 23s 790ms/step - loss: 1.2575 - accuracy: 0.7560 - val_loss: 2.7515 - val_accuracy: 0.5033\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 23s 792ms/step - loss: 1.2556 - accuracy: 0.7200 - val_loss: 5.8716 - val_accuracy: 0.2092\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 23s 791ms/step - loss: 1.0518 - accuracy: 0.7658 - val_loss: 4.8617 - val_accuracy: 0.4085\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 23s 798ms/step - loss: 1.0014 - accuracy: 0.7571 - val_loss: 3.2654 - val_accuracy: 0.5229\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 0.7584 - accuracy: 0.8061 - val_loss: 0.8634 - val_accuracy: 0.7288\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 23s 801ms/step - loss: 0.7227 - accuracy: 0.8007 - val_loss: 1.2760 - val_accuracy: 0.6667\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 0.7668 - accuracy: 0.7810 - val_loss: 2.3442 - val_accuracy: 0.5327\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 23s 798ms/step - loss: 0.7027 - accuracy: 0.8126 - val_loss: 3.5143 - val_accuracy: 0.4804\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 23s 792ms/step - loss: 0.5467 - accuracy: 0.8279 - val_loss: 4.0872 - val_accuracy: 0.4412\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 23s 797ms/step - loss: 0.6467 - accuracy: 0.8431 - val_loss: 7.0724 - val_accuracy: 0.2124\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 23s 803ms/step - loss: 0.5534 - accuracy: 0.8453 - val_loss: 1.8609 - val_accuracy: 0.6830\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 23s 793ms/step - loss: 0.5822 - accuracy: 0.8301 - val_loss: 3.1993 - val_accuracy: 0.5654\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 23s 797ms/step - loss: 0.6511 - accuracy: 0.8312 - val_loss: 3.6355 - val_accuracy: 0.6013\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 23s 795ms/step - loss: 0.5920 - accuracy: 0.8431 - val_loss: 1.6790 - val_accuracy: 0.5784\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 23s 808ms/step - loss: 0.5640 - accuracy: 0.8638 - val_loss: 1.6159 - val_accuracy: 0.6405\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 23s 802ms/step - loss: 0.5289 - accuracy: 0.8638 - val_loss: 4.2171 - val_accuracy: 0.4085\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 23s 793ms/step - loss: 0.4665 - accuracy: 0.8486 - val_loss: 29.6513 - val_accuracy: 0.0915\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 23s 801ms/step - loss: 0.6400 - accuracy: 0.8573 - val_loss: 62.5581 - val_accuracy: 0.1144\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 23s 796ms/step - loss: 0.7630 - accuracy: 0.8257 - val_loss: 8.6985 - val_accuracy: 0.5490\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 0.8559 - accuracy: 0.8159 - val_loss: 19.6889 - val_accuracy: 0.1013\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 23s 800ms/step - loss: 1.2436 - accuracy: 0.7429 - val_loss: 14.5332 - val_accuracy: 0.2876\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 23s 806ms/step - loss: 1.2397 - accuracy: 0.7277 - val_loss: 2.3563 - val_accuracy: 0.7092\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 1.0434 - accuracy: 0.7810 - val_loss: 23.6757 - val_accuracy: 0.3562\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 23s 798ms/step - loss: 1.1235 - accuracy: 0.7854 - val_loss: 12.7404 - val_accuracy: 0.1732\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 23s 794ms/step - loss: 0.9224 - accuracy: 0.8137 - val_loss: 2.4388 - val_accuracy: 0.6536\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 0.7948 - accuracy: 0.8224 - val_loss: 3.2557 - val_accuracy: 0.7288\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 23s 793ms/step - loss: 0.9583 - accuracy: 0.8203 - val_loss: 8.4032 - val_accuracy: 0.3268\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 23s 798ms/step - loss: 0.8707 - accuracy: 0.8246 - val_loss: 6.4665 - val_accuracy: 0.3889\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 1.0292 - accuracy: 0.8214 - val_loss: 5.2456 - val_accuracy: 0.5752\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 23s 798ms/step - loss: 0.9436 - accuracy: 0.8486 - val_loss: 9.4657 - val_accuracy: 0.5163\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 23s 793ms/step - loss: 0.8631 - accuracy: 0.8410 - val_loss: 4.1436 - val_accuracy: 0.5654\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 23s 791ms/step - loss: 0.9215 - accuracy: 0.8366 - val_loss: 7.1531 - val_accuracy: 0.3562\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 23s 801ms/step - loss: 0.8880 - accuracy: 0.8627 - val_loss: 12.3632 - val_accuracy: 0.2353\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 23s 798ms/step - loss: 0.8104 - accuracy: 0.8475 - val_loss: 14.9182 - val_accuracy: 0.2843\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 23s 793ms/step - loss: 0.6595 - accuracy: 0.8649 - val_loss: 4.5937 - val_accuracy: 0.5261\n",
      "Epoch 1/200\n",
      "29/29 [==============================] - 23s 778ms/step - loss: 1.7784 - accuracy: 0.5044 - val_loss: 2.9708 - val_accuracy: 0.0033\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 22s 756ms/step - loss: 1.0789 - accuracy: 0.6808 - val_loss: 2.9645 - val_accuracy: 0.0752\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 22s 758ms/step - loss: 0.8655 - accuracy: 0.7320 - val_loss: 6.6555 - val_accuracy: 0.2026\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 22s 757ms/step - loss: 0.7628 - accuracy: 0.7636 - val_loss: 6.1071 - val_accuracy: 0.2026\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 22s 764ms/step - loss: 0.6574 - accuracy: 0.7930 - val_loss: 8.2037 - val_accuracy: 0.2026\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 22s 767ms/step - loss: 0.6025 - accuracy: 0.8235 - val_loss: 4.8213 - val_accuracy: 0.2026\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 22s 766ms/step - loss: 0.5481 - accuracy: 0.8148 - val_loss: 7.9413 - val_accuracy: 0.0752\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 22s 767ms/step - loss: 0.5450 - accuracy: 0.8159 - val_loss: 9.0799 - val_accuracy: 0.2026\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 22s 762ms/step - loss: 0.4262 - accuracy: 0.8660 - val_loss: 8.0868 - val_accuracy: 0.0752\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 22s 760ms/step - loss: 0.4460 - accuracy: 0.8497 - val_loss: 20.8015 - val_accuracy: 0.2026\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 22s 766ms/step - loss: 0.4155 - accuracy: 0.8682 - val_loss: 9.0719 - val_accuracy: 0.2026\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 22s 770ms/step - loss: 0.3775 - accuracy: 0.8769 - val_loss: 11.8212 - val_accuracy: 0.2026\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 22s 769ms/step - loss: 0.3448 - accuracy: 0.8834 - val_loss: 8.0829 - val_accuracy: 0.2026\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 22s 764ms/step - loss: 0.3287 - accuracy: 0.8911 - val_loss: 9.4148 - val_accuracy: 0.2026\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 22s 768ms/step - loss: 0.2794 - accuracy: 0.9063 - val_loss: 8.2073 - val_accuracy: 0.2026\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 22s 774ms/step - loss: 0.2707 - accuracy: 0.9074 - val_loss: 8.4280 - val_accuracy: 0.2026\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 22s 773ms/step - loss: 0.2832 - accuracy: 0.9118 - val_loss: 8.8249 - val_accuracy: 0.2026\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 22s 769ms/step - loss: 0.2714 - accuracy: 0.9259 - val_loss: 6.6351 - val_accuracy: 0.2255\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 22s 766ms/step - loss: 0.2245 - accuracy: 0.9270 - val_loss: 8.9556 - val_accuracy: 0.2026\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 22s 772ms/step - loss: 0.2311 - accuracy: 0.9270 - val_loss: 6.7231 - val_accuracy: 0.2092\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 22s 766ms/step - loss: 0.2385 - accuracy: 0.9107 - val_loss: 7.0617 - val_accuracy: 0.2059\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 22s 771ms/step - loss: 0.2252 - accuracy: 0.9292 - val_loss: 5.3034 - val_accuracy: 0.2386\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 22s 761ms/step - loss: 0.1870 - accuracy: 0.9412 - val_loss: 6.7888 - val_accuracy: 0.2190\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 22s 767ms/step - loss: 0.2298 - accuracy: 0.9281 - val_loss: 3.7184 - val_accuracy: 0.3137\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 22s 770ms/step - loss: 0.1902 - accuracy: 0.9357 - val_loss: 4.0964 - val_accuracy: 0.3235\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 22s 760ms/step - loss: 0.1716 - accuracy: 0.9434 - val_loss: 4.0146 - val_accuracy: 0.3366\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 22s 760ms/step - loss: 0.1474 - accuracy: 0.9532 - val_loss: 4.5896 - val_accuracy: 0.2941\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 22s 758ms/step - loss: 0.1585 - accuracy: 0.9488 - val_loss: 4.1425 - val_accuracy: 0.3366\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 22s 763ms/step - loss: 0.1410 - accuracy: 0.9575 - val_loss: 3.6052 - val_accuracy: 0.3922\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 22s 763ms/step - loss: 0.1474 - accuracy: 0.9542 - val_loss: 2.4241 - val_accuracy: 0.5131\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 22s 767ms/step - loss: 0.1300 - accuracy: 0.9586 - val_loss: 2.4353 - val_accuracy: 0.4641\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 22s 769ms/step - loss: 0.1379 - accuracy: 0.9564 - val_loss: 2.5598 - val_accuracy: 0.4641\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 22s 762ms/step - loss: 0.1678 - accuracy: 0.9553 - val_loss: 7.7011 - val_accuracy: 0.1569\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 22s 758ms/step - loss: 0.1365 - accuracy: 0.9553 - val_loss: 125.1243 - val_accuracy: 0.0752\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 22s 758ms/step - loss: 0.1101 - accuracy: 0.9641 - val_loss: 3.6172 - val_accuracy: 0.3660\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 22s 759ms/step - loss: 0.1301 - accuracy: 0.9608 - val_loss: 3.6031 - val_accuracy: 0.3889\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 22s 754ms/step - loss: 0.1270 - accuracy: 0.9575 - val_loss: 3.4105 - val_accuracy: 0.4052\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 22s 764ms/step - loss: 0.1120 - accuracy: 0.9728 - val_loss: 2.8314 - val_accuracy: 0.4085\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 22s 757ms/step - loss: 0.1051 - accuracy: 0.9695 - val_loss: 3.2520 - val_accuracy: 0.3954\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 22s 757ms/step - loss: 0.1092 - accuracy: 0.9739 - val_loss: 3.6312 - val_accuracy: 0.3824\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 22s 760ms/step - loss: 0.0941 - accuracy: 0.9728 - val_loss: 3.3347 - val_accuracy: 0.4085\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 22s 762ms/step - loss: 0.0969 - accuracy: 0.9717 - val_loss: 3.0857 - val_accuracy: 0.4314\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 22s 760ms/step - loss: 0.0974 - accuracy: 0.9695 - val_loss: 2.4016 - val_accuracy: 0.5458\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 22s 756ms/step - loss: 0.0960 - accuracy: 0.9728 - val_loss: 3.2330 - val_accuracy: 0.4020\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 22s 758ms/step - loss: 0.0938 - accuracy: 0.9717 - val_loss: 2.8216 - val_accuracy: 0.4902\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 22s 755ms/step - loss: 0.0933 - accuracy: 0.9749 - val_loss: 2.3486 - val_accuracy: 0.5458\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 22s 763ms/step - loss: 0.0909 - accuracy: 0.9771 - val_loss: 2.6265 - val_accuracy: 0.4869\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 23s 784ms/step - loss: 0.0916 - accuracy: 0.9717 - val_loss: 2.4945 - val_accuracy: 0.4837\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 23s 790ms/step - loss: 0.0699 - accuracy: 0.9891 - val_loss: 2.3622 - val_accuracy: 0.4935\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 23s 780ms/step - loss: 0.0765 - accuracy: 0.9837 - val_loss: 2.3529 - val_accuracy: 0.4739\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 23s 777ms/step - loss: 0.0906 - accuracy: 0.9749 - val_loss: 3.0198 - val_accuracy: 0.4314\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 22s 771ms/step - loss: 0.0793 - accuracy: 0.9804 - val_loss: 2.8994 - val_accuracy: 0.4346\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 23s 778ms/step - loss: 0.0759 - accuracy: 0.9804 - val_loss: 1.8896 - val_accuracy: 0.5719\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 22s 773ms/step - loss: 0.0708 - accuracy: 0.9804 - val_loss: 2.9794 - val_accuracy: 0.4641\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 22s 771ms/step - loss: 0.0705 - accuracy: 0.9771 - val_loss: 2.5854 - val_accuracy: 0.4510\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 22s 775ms/step - loss: 0.0748 - accuracy: 0.9771 - val_loss: 2.6334 - val_accuracy: 0.5131\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 22s 776ms/step - loss: 0.0542 - accuracy: 0.9847 - val_loss: 2.7097 - val_accuracy: 0.4379\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 22s 770ms/step - loss: 0.0765 - accuracy: 0.9826 - val_loss: 2.0974 - val_accuracy: 0.5294\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 22s 770ms/step - loss: 0.0619 - accuracy: 0.9826 - val_loss: 2.4515 - val_accuracy: 0.4510\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 23s 777ms/step - loss: 0.0758 - accuracy: 0.9793 - val_loss: 1.9683 - val_accuracy: 0.5621\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 23s 777ms/step - loss: 0.0770 - accuracy: 0.9837 - val_loss: 2.4504 - val_accuracy: 0.5163\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 22s 776ms/step - loss: 0.0496 - accuracy: 0.9880 - val_loss: 2.0904 - val_accuracy: 0.5523\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 23s 779ms/step - loss: 0.0530 - accuracy: 0.9880 - val_loss: 2.0208 - val_accuracy: 0.5621\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 23s 777ms/step - loss: 0.0725 - accuracy: 0.9717 - val_loss: 1.7506 - val_accuracy: 0.5915\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 23s 783ms/step - loss: 0.0642 - accuracy: 0.9837 - val_loss: 1.8816 - val_accuracy: 0.5588\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 22s 776ms/step - loss: 0.0798 - accuracy: 0.9793 - val_loss: 2.3766 - val_accuracy: 0.5294\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 23s 781ms/step - loss: 0.0675 - accuracy: 0.9858 - val_loss: 2.1816 - val_accuracy: 0.5425\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 23s 778ms/step - loss: 0.0578 - accuracy: 0.9847 - val_loss: 1.6725 - val_accuracy: 0.5621\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 23s 780ms/step - loss: 0.0503 - accuracy: 0.9913 - val_loss: 1.6675 - val_accuracy: 0.5784\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 23s 777ms/step - loss: 0.0447 - accuracy: 0.9880 - val_loss: 1.8033 - val_accuracy: 0.5621\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 23s 788ms/step - loss: 0.0493 - accuracy: 0.9902 - val_loss: 1.8010 - val_accuracy: 0.5588\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 23s 782ms/step - loss: 0.0456 - accuracy: 0.9891 - val_loss: 1.7496 - val_accuracy: 0.5686\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 23s 780ms/step - loss: 0.0477 - accuracy: 0.9858 - val_loss: 1.7089 - val_accuracy: 0.5719\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 23s 779ms/step - loss: 0.0576 - accuracy: 0.9858 - val_loss: 1.6864 - val_accuracy: 0.5752\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 22s 769ms/step - loss: 0.0568 - accuracy: 0.9837 - val_loss: 1.4808 - val_accuracy: 0.6111\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 22s 774ms/step - loss: 0.0472 - accuracy: 0.9902 - val_loss: 1.8819 - val_accuracy: 0.5359\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 23s 780ms/step - loss: 0.0442 - accuracy: 0.9902 - val_loss: 1.7115 - val_accuracy: 0.5654\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 22s 769ms/step - loss: 0.0548 - accuracy: 0.9869 - val_loss: 1.8112 - val_accuracy: 0.5654\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 23s 782ms/step - loss: 0.0383 - accuracy: 0.9935 - val_loss: 2.0925 - val_accuracy: 0.5098\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 23s 777ms/step - loss: 0.0627 - accuracy: 0.9793 - val_loss: 1.9258 - val_accuracy: 0.5588\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 23s 781ms/step - loss: 0.0430 - accuracy: 0.9880 - val_loss: 1.9820 - val_accuracy: 0.5425\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 23s 778ms/step - loss: 0.0505 - accuracy: 0.9858 - val_loss: 1.7255 - val_accuracy: 0.6078\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 23s 777ms/step - loss: 0.0385 - accuracy: 0.9946 - val_loss: 1.7121 - val_accuracy: 0.5948\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 22s 771ms/step - loss: 0.0572 - accuracy: 0.9858 - val_loss: 1.7094 - val_accuracy: 0.5719\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 22s 773ms/step - loss: 0.0502 - accuracy: 0.9913 - val_loss: 1.5934 - val_accuracy: 0.6078\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 22s 771ms/step - loss: 0.0403 - accuracy: 0.9946 - val_loss: 1.4589 - val_accuracy: 0.6307\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 22s 764ms/step - loss: 0.0410 - accuracy: 0.9891 - val_loss: 1.4780 - val_accuracy: 0.6242\n",
      "Epoch 88/200\n",
      "29/29 [==============================] - 23s 778ms/step - loss: 0.0503 - accuracy: 0.9880 - val_loss: 1.6192 - val_accuracy: 0.6046\n",
      "Epoch 89/200\n",
      "29/29 [==============================] - 23s 785ms/step - loss: 0.0405 - accuracy: 0.9946 - val_loss: 1.6718 - val_accuracy: 0.6144\n",
      "Epoch 90/200\n",
      "29/29 [==============================] - 22s 773ms/step - loss: 0.0418 - accuracy: 0.9913 - val_loss: 1.7889 - val_accuracy: 0.5686\n",
      "Epoch 91/200\n",
      "29/29 [==============================] - 26s 906ms/step - loss: 0.0474 - accuracy: 0.9869 - val_loss: 1.9221 - val_accuracy: 0.5621\n",
      "Epoch 92/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0457 - accuracy: 0.9869 - val_loss: 2.1604 - val_accuracy: 0.5425\n",
      "Epoch 93/200\n",
      "29/29 [==============================] - 26s 905ms/step - loss: 0.0455 - accuracy: 0.9891 - val_loss: 1.7803 - val_accuracy: 0.5719\n",
      "Epoch 94/200\n",
      "29/29 [==============================] - 27s 928ms/step - loss: 0.0452 - accuracy: 0.9880 - val_loss: 1.7165 - val_accuracy: 0.5817\n",
      "Epoch 95/200\n",
      "29/29 [==============================] - 26s 909ms/step - loss: 0.0636 - accuracy: 0.9858 - val_loss: 1.7992 - val_accuracy: 0.5719\n",
      "Epoch 96/200\n",
      "29/29 [==============================] - 26s 911ms/step - loss: 0.0538 - accuracy: 0.9847 - val_loss: 1.9397 - val_accuracy: 0.5654\n",
      "Epoch 97/200\n",
      "29/29 [==============================] - 26s 898ms/step - loss: 0.0420 - accuracy: 0.9913 - val_loss: 1.7394 - val_accuracy: 0.5817\n",
      "Epoch 98/200\n",
      "29/29 [==============================] - 27s 917ms/step - loss: 0.0446 - accuracy: 0.9924 - val_loss: 1.9632 - val_accuracy: 0.5425\n",
      "Epoch 99/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0415 - accuracy: 0.9880 - val_loss: 1.7718 - val_accuracy: 0.5719\n",
      "Epoch 100/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0491 - accuracy: 0.9913 - val_loss: 1.8088 - val_accuracy: 0.5621\n",
      "Epoch 101/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0450 - accuracy: 0.9880 - val_loss: 1.7010 - val_accuracy: 0.5980\n",
      "Epoch 102/200\n",
      "29/29 [==============================] - 31s 1s/step - loss: 0.0347 - accuracy: 0.9935 - val_loss: 1.7728 - val_accuracy: 0.6013\n",
      "Epoch 103/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0467 - accuracy: 0.9869 - val_loss: 1.6347 - val_accuracy: 0.6242\n",
      "Epoch 104/200\n",
      "29/29 [==============================] - 31s 1s/step - loss: 0.0338 - accuracy: 0.9902 - val_loss: 1.7756 - val_accuracy: 0.5882\n",
      "Epoch 105/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0413 - accuracy: 0.9880 - val_loss: 1.7631 - val_accuracy: 0.5980\n",
      "Epoch 106/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0311 - accuracy: 0.9956 - val_loss: 1.9484 - val_accuracy: 0.5588\n",
      "Epoch 107/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0458 - accuracy: 0.9847 - val_loss: 1.8450 - val_accuracy: 0.5752\n",
      "Epoch 108/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0388 - accuracy: 0.9891 - val_loss: 1.7344 - val_accuracy: 0.6013\n",
      "Epoch 109/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0398 - accuracy: 0.9902 - val_loss: 1.6588 - val_accuracy: 0.6144\n",
      "Epoch 110/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0385 - accuracy: 0.9902 - val_loss: 1.5665 - val_accuracy: 0.6275\n",
      "Epoch 111/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0270 - accuracy: 0.9946 - val_loss: 1.4886 - val_accuracy: 0.6242\n",
      "Epoch 112/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0363 - accuracy: 0.9902 - val_loss: 1.4453 - val_accuracy: 0.6405\n",
      "Epoch 113/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0327 - accuracy: 0.9946 - val_loss: 1.6351 - val_accuracy: 0.6111\n",
      "Epoch 114/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0378 - accuracy: 0.9913 - val_loss: 1.7617 - val_accuracy: 0.5817\n",
      "Epoch 115/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0459 - accuracy: 0.9869 - val_loss: 1.7528 - val_accuracy: 0.5850\n",
      "Epoch 116/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0496 - accuracy: 0.9880 - val_loss: 1.6699 - val_accuracy: 0.5980\n",
      "Epoch 117/200\n",
      "29/29 [==============================] - 32s 1s/step - loss: 0.0289 - accuracy: 0.9946 - val_loss: 1.6299 - val_accuracy: 0.6176\n",
      "Epoch 118/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0521 - accuracy: 0.9880 - val_loss: 1.6148 - val_accuracy: 0.6111\n",
      "Epoch 119/200\n",
      "29/29 [==============================] - 31s 1s/step - loss: 0.0314 - accuracy: 0.9956 - val_loss: 1.7250 - val_accuracy: 0.5980\n",
      "Epoch 120/200\n",
      "29/29 [==============================] - 23s 791ms/step - loss: 0.0396 - accuracy: 0.9902 - val_loss: 1.5778 - val_accuracy: 0.6176\n",
      "Epoch 121/200\n",
      "29/29 [==============================] - 21s 736ms/step - loss: 0.0376 - accuracy: 0.9902 - val_loss: 1.6071 - val_accuracy: 0.6144\n",
      "Epoch 122/200\n",
      "29/29 [==============================] - 21s 737ms/step - loss: 0.0386 - accuracy: 0.9924 - val_loss: 1.7152 - val_accuracy: 0.5980\n",
      "Epoch 123/200\n",
      "29/29 [==============================] - 21s 734ms/step - loss: 0.0275 - accuracy: 0.9956 - val_loss: 1.5993 - val_accuracy: 0.6275\n",
      "Epoch 124/200\n",
      "29/29 [==============================] - 21s 730ms/step - loss: 0.0363 - accuracy: 0.9946 - val_loss: 1.7885 - val_accuracy: 0.6078\n",
      "Epoch 125/200\n",
      "29/29 [==============================] - 21s 730ms/step - loss: 0.0469 - accuracy: 0.9869 - val_loss: 1.6551 - val_accuracy: 0.6176\n",
      "Epoch 126/200\n",
      "29/29 [==============================] - 21s 736ms/step - loss: 0.0306 - accuracy: 0.9935 - val_loss: 1.7789 - val_accuracy: 0.5882\n",
      "Epoch 127/200\n",
      "29/29 [==============================] - 21s 730ms/step - loss: 0.0282 - accuracy: 0.9946 - val_loss: 1.8277 - val_accuracy: 0.5752\n",
      "Epoch 128/200\n",
      "29/29 [==============================] - 21s 723ms/step - loss: 0.0290 - accuracy: 0.9924 - val_loss: 1.8645 - val_accuracy: 0.5882\n",
      "Epoch 129/200\n",
      "29/29 [==============================] - 21s 730ms/step - loss: 0.0457 - accuracy: 0.9880 - val_loss: 1.7259 - val_accuracy: 0.5915\n",
      "Epoch 130/200\n",
      "29/29 [==============================] - 21s 734ms/step - loss: 0.0243 - accuracy: 0.9978 - val_loss: 1.7539 - val_accuracy: 0.5784\n",
      "Epoch 131/200\n",
      "29/29 [==============================] - 21s 734ms/step - loss: 0.0331 - accuracy: 0.9946 - val_loss: 1.7312 - val_accuracy: 0.5850\n",
      "Epoch 132/200\n",
      "29/29 [==============================] - 21s 725ms/step - loss: 0.0416 - accuracy: 0.9902 - val_loss: 1.7549 - val_accuracy: 0.5784\n",
      "Epoch 133/200\n",
      "29/29 [==============================] - 21s 727ms/step - loss: 0.0406 - accuracy: 0.9869 - val_loss: 1.7315 - val_accuracy: 0.5850\n",
      "Epoch 134/200\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 0.0380 - accuracy: 0.9924 - val_loss: 1.6954 - val_accuracy: 0.5915\n",
      "Epoch 135/200\n",
      "29/29 [==============================] - 21s 728ms/step - loss: 0.0312 - accuracy: 0.9956 - val_loss: 1.7179 - val_accuracy: 0.5817\n",
      "Epoch 136/200\n",
      "29/29 [==============================] - 21s 729ms/step - loss: 0.0286 - accuracy: 0.9935 - val_loss: 1.6545 - val_accuracy: 0.5980\n",
      "Epoch 137/200\n",
      "29/29 [==============================] - 21s 729ms/step - loss: 0.0318 - accuracy: 0.9935 - val_loss: 1.6643 - val_accuracy: 0.5948\n",
      "Epoch 138/200\n",
      "29/29 [==============================] - 21s 729ms/step - loss: 0.0406 - accuracy: 0.9880 - val_loss: 1.6645 - val_accuracy: 0.5915\n",
      "Epoch 139/200\n",
      "29/29 [==============================] - 21s 720ms/step - loss: 0.0388 - accuracy: 0.9913 - val_loss: 1.6222 - val_accuracy: 0.5948\n",
      "Epoch 140/200\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.0560 - accuracy: 0.9869 - val_loss: 1.5038 - val_accuracy: 0.6340\n",
      "Epoch 141/200\n",
      "29/29 [==============================] - 21s 727ms/step - loss: 0.0347 - accuracy: 0.9924 - val_loss: 1.6540 - val_accuracy: 0.5948\n",
      "Epoch 142/200\n",
      "29/29 [==============================] - 21s 730ms/step - loss: 0.0230 - accuracy: 0.9956 - val_loss: 1.6738 - val_accuracy: 0.5915\n",
      "Epoch 1/200\n",
      "29/29 [==============================] - 22s 726ms/step - loss: 2.1523 - accuracy: 0.4074 - val_loss: 4.1276 - val_accuracy: 0.0752\n",
      "Epoch 2/200\n",
      "29/29 [==============================] - 21s 714ms/step - loss: 1.3226 - accuracy: 0.6383 - val_loss: 3.1584 - val_accuracy: 0.2026\n",
      "Epoch 3/200\n",
      "29/29 [==============================] - 21s 727ms/step - loss: 0.9558 - accuracy: 0.6885 - val_loss: 4.0211 - val_accuracy: 0.2026\n",
      "Epoch 4/200\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.7883 - accuracy: 0.7614 - val_loss: 6.1809 - val_accuracy: 0.2190\n",
      "Epoch 5/200\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.7259 - accuracy: 0.7691 - val_loss: 8.6123 - val_accuracy: 0.2026\n",
      "Epoch 6/200\n",
      "29/29 [==============================] - 21s 717ms/step - loss: 0.6457 - accuracy: 0.7865 - val_loss: 10.5915 - val_accuracy: 0.2026\n",
      "Epoch 7/200\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.5372 - accuracy: 0.8322 - val_loss: 7.5616 - val_accuracy: 0.2092\n",
      "Epoch 8/200\n",
      "29/29 [==============================] - 21s 715ms/step - loss: 0.5223 - accuracy: 0.8279 - val_loss: 7.0095 - val_accuracy: 0.2059\n",
      "Epoch 9/200\n",
      "29/29 [==============================] - 21s 712ms/step - loss: 0.5209 - accuracy: 0.8420 - val_loss: 5.6500 - val_accuracy: 0.2222\n",
      "Epoch 10/200\n",
      "29/29 [==============================] - 21s 714ms/step - loss: 0.5060 - accuracy: 0.8431 - val_loss: 4.6251 - val_accuracy: 0.2614\n",
      "Epoch 11/200\n",
      "29/29 [==============================] - 21s 710ms/step - loss: 0.4279 - accuracy: 0.8617 - val_loss: 3.4368 - val_accuracy: 0.2843\n",
      "Epoch 12/200\n",
      "29/29 [==============================] - 21s 717ms/step - loss: 0.4284 - accuracy: 0.8649 - val_loss: 4.3259 - val_accuracy: 0.2451\n",
      "Epoch 13/200\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.4365 - accuracy: 0.8606 - val_loss: 4.4672 - val_accuracy: 0.2843\n",
      "Epoch 14/200\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.3958 - accuracy: 0.8802 - val_loss: 4.6775 - val_accuracy: 0.2680\n",
      "Epoch 15/200\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.3553 - accuracy: 0.8911 - val_loss: 3.6973 - val_accuracy: 0.3039\n",
      "Epoch 16/200\n",
      "29/29 [==============================] - 21s 711ms/step - loss: 0.3700 - accuracy: 0.8834 - val_loss: 3.3593 - val_accuracy: 0.3464\n",
      "Epoch 17/200\n",
      "29/29 [==============================] - 21s 709ms/step - loss: 0.2951 - accuracy: 0.9041 - val_loss: 2.0984 - val_accuracy: 0.5294\n",
      "Epoch 18/200\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.2787 - accuracy: 0.9063 - val_loss: 1.9844 - val_accuracy: 0.5490\n",
      "Epoch 19/200\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 0.2939 - accuracy: 0.8954 - val_loss: 1.9834 - val_accuracy: 0.5196\n",
      "Epoch 20/200\n",
      "29/29 [==============================] - 21s 714ms/step - loss: 0.2554 - accuracy: 0.9139 - val_loss: 2.1918 - val_accuracy: 0.4608\n",
      "Epoch 21/200\n",
      "29/29 [==============================] - 21s 709ms/step - loss: 0.2407 - accuracy: 0.9129 - val_loss: 1.7883 - val_accuracy: 0.5882\n",
      "Epoch 22/200\n",
      "29/29 [==============================] - 21s 714ms/step - loss: 0.2154 - accuracy: 0.9434 - val_loss: 1.5894 - val_accuracy: 0.6176\n",
      "Epoch 23/200\n",
      "29/29 [==============================] - 20s 708ms/step - loss: 0.2146 - accuracy: 0.9248 - val_loss: 1.8769 - val_accuracy: 0.5686\n",
      "Epoch 24/200\n",
      "29/29 [==============================] - 21s 707ms/step - loss: 0.2375 - accuracy: 0.9096 - val_loss: 1.8009 - val_accuracy: 0.5621\n",
      "Epoch 25/200\n",
      "29/29 [==============================] - 21s 715ms/step - loss: 0.2106 - accuracy: 0.9259 - val_loss: 1.5140 - val_accuracy: 0.6503\n",
      "Epoch 26/200\n",
      "29/29 [==============================] - 21s 711ms/step - loss: 0.1591 - accuracy: 0.9553 - val_loss: 1.5618 - val_accuracy: 0.6503\n",
      "Epoch 27/200\n",
      "29/29 [==============================] - 20s 703ms/step - loss: 0.1696 - accuracy: 0.9423 - val_loss: 1.3134 - val_accuracy: 0.7059\n",
      "Epoch 28/200\n",
      "29/29 [==============================] - 21s 721ms/step - loss: 0.1561 - accuracy: 0.9521 - val_loss: 1.4124 - val_accuracy: 0.6536\n",
      "Epoch 29/200\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 0.1669 - accuracy: 0.9434 - val_loss: 1.2252 - val_accuracy: 0.7059\n",
      "Epoch 30/200\n",
      "29/29 [==============================] - 21s 710ms/step - loss: 0.1508 - accuracy: 0.9575 - val_loss: 1.3852 - val_accuracy: 0.7092\n",
      "Epoch 31/200\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.1681 - accuracy: 0.9477 - val_loss: 1.5741 - val_accuracy: 0.6503\n",
      "Epoch 32/200\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.1406 - accuracy: 0.9586 - val_loss: 1.4116 - val_accuracy: 0.7026\n",
      "Epoch 33/200\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.1221 - accuracy: 0.9542 - val_loss: 1.1446 - val_accuracy: 0.7320\n",
      "Epoch 34/200\n",
      "29/29 [==============================] - 20s 707ms/step - loss: 0.1321 - accuracy: 0.9608 - val_loss: 1.1304 - val_accuracy: 0.6993\n",
      "Epoch 35/200\n",
      "29/29 [==============================] - 20s 704ms/step - loss: 0.1120 - accuracy: 0.9684 - val_loss: 1.3153 - val_accuracy: 0.6993\n",
      "Epoch 36/200\n",
      "29/29 [==============================] - 22s 771ms/step - loss: 0.1076 - accuracy: 0.9673 - val_loss: 1.2277 - val_accuracy: 0.7222\n",
      "Epoch 37/200\n",
      "29/29 [==============================] - 23s 807ms/step - loss: 0.1058 - accuracy: 0.9651 - val_loss: 1.2238 - val_accuracy: 0.7320\n",
      "Epoch 38/200\n",
      "29/29 [==============================] - 21s 723ms/step - loss: 0.0951 - accuracy: 0.9662 - val_loss: 1.3326 - val_accuracy: 0.6993\n",
      "Epoch 39/200\n",
      "29/29 [==============================] - 22s 751ms/step - loss: 0.0965 - accuracy: 0.9684 - val_loss: 1.3787 - val_accuracy: 0.6993\n",
      "Epoch 40/200\n",
      "29/29 [==============================] - 24s 824ms/step - loss: 0.0845 - accuracy: 0.9771 - val_loss: 1.2827 - val_accuracy: 0.7222\n",
      "Epoch 41/200\n",
      "29/29 [==============================] - 25s 850ms/step - loss: 0.0883 - accuracy: 0.9684 - val_loss: 1.1306 - val_accuracy: 0.7353\n",
      "Epoch 42/200\n",
      "29/29 [==============================] - 23s 799ms/step - loss: 0.0948 - accuracy: 0.9717 - val_loss: 1.0657 - val_accuracy: 0.7222\n",
      "Epoch 43/200\n",
      "29/29 [==============================] - 23s 779ms/step - loss: 0.0973 - accuracy: 0.9662 - val_loss: 1.2879 - val_accuracy: 0.7255\n",
      "Epoch 44/200\n",
      "29/29 [==============================] - 23s 779ms/step - loss: 0.0799 - accuracy: 0.9684 - val_loss: 1.2092 - val_accuracy: 0.7092\n",
      "Epoch 45/200\n",
      "29/29 [==============================] - 23s 797ms/step - loss: 0.0890 - accuracy: 0.9673 - val_loss: 1.0333 - val_accuracy: 0.7092\n",
      "Epoch 46/200\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.0773 - accuracy: 0.9771 - val_loss: 1.0647 - val_accuracy: 0.7386\n",
      "Epoch 47/200\n",
      "29/29 [==============================] - 21s 712ms/step - loss: 0.0741 - accuracy: 0.9771 - val_loss: 1.1989 - val_accuracy: 0.7026\n",
      "Epoch 48/200\n",
      "29/29 [==============================] - 21s 709ms/step - loss: 0.0625 - accuracy: 0.9837 - val_loss: 1.2840 - val_accuracy: 0.7026\n",
      "Epoch 49/200\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 0.0682 - accuracy: 0.9771 - val_loss: 1.3393 - val_accuracy: 0.7124\n",
      "Epoch 50/200\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.0610 - accuracy: 0.9771 - val_loss: 1.2379 - val_accuracy: 0.7255\n",
      "Epoch 51/200\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 0.0640 - accuracy: 0.9815 - val_loss: 1.1617 - val_accuracy: 0.7320\n",
      "Epoch 52/200\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.0635 - accuracy: 0.9749 - val_loss: 1.0618 - val_accuracy: 0.7320\n",
      "Epoch 53/200\n",
      "29/29 [==============================] - 21s 722ms/step - loss: 0.0664 - accuracy: 0.9826 - val_loss: 1.0488 - val_accuracy: 0.7124\n",
      "Epoch 54/200\n",
      "29/29 [==============================] - 21s 723ms/step - loss: 0.0664 - accuracy: 0.9826 - val_loss: 1.0248 - val_accuracy: 0.7222\n",
      "Epoch 55/200\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.0697 - accuracy: 0.9760 - val_loss: 1.0192 - val_accuracy: 0.7320\n",
      "Epoch 56/200\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.0602 - accuracy: 0.9826 - val_loss: 1.1570 - val_accuracy: 0.7092\n",
      "Epoch 57/200\n",
      "29/29 [==============================] - 21s 710ms/step - loss: 0.0507 - accuracy: 0.9858 - val_loss: 1.2075 - val_accuracy: 0.7026\n",
      "Epoch 58/200\n",
      "29/29 [==============================] - 21s 727ms/step - loss: 0.0654 - accuracy: 0.9815 - val_loss: 1.1942 - val_accuracy: 0.7059\n",
      "Epoch 59/200\n",
      "29/29 [==============================] - 21s 712ms/step - loss: 0.0481 - accuracy: 0.9837 - val_loss: 0.9546 - val_accuracy: 0.7451\n",
      "Epoch 60/200\n",
      "29/29 [==============================] - 21s 720ms/step - loss: 0.0579 - accuracy: 0.9749 - val_loss: 1.0263 - val_accuracy: 0.7386\n",
      "Epoch 61/200\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.0605 - accuracy: 0.9804 - val_loss: 1.2347 - val_accuracy: 0.7353\n",
      "Epoch 62/200\n",
      "29/29 [==============================] - 21s 711ms/step - loss: 0.0569 - accuracy: 0.9826 - val_loss: 1.3992 - val_accuracy: 0.7092\n",
      "Epoch 63/200\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.0389 - accuracy: 0.9869 - val_loss: 1.2930 - val_accuracy: 0.7255\n",
      "Epoch 64/200\n",
      "29/29 [==============================] - 21s 714ms/step - loss: 0.0690 - accuracy: 0.9804 - val_loss: 1.1229 - val_accuracy: 0.7353\n",
      "Epoch 65/200\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.0628 - accuracy: 0.9815 - val_loss: 1.1106 - val_accuracy: 0.7222\n",
      "Epoch 66/200\n",
      "29/29 [==============================] - 21s 714ms/step - loss: 0.0559 - accuracy: 0.9847 - val_loss: 1.1807 - val_accuracy: 0.6928\n",
      "Epoch 67/200\n",
      "29/29 [==============================] - 20s 706ms/step - loss: 0.0529 - accuracy: 0.9847 - val_loss: 1.1090 - val_accuracy: 0.7190\n",
      "Epoch 68/200\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.0412 - accuracy: 0.9847 - val_loss: 1.2191 - val_accuracy: 0.7255\n",
      "Epoch 69/200\n",
      "29/29 [==============================] - 21s 717ms/step - loss: 0.0500 - accuracy: 0.9880 - val_loss: 1.3426 - val_accuracy: 0.7222\n",
      "Epoch 70/200\n",
      "29/29 [==============================] - 21s 710ms/step - loss: 0.0530 - accuracy: 0.9826 - val_loss: 1.4047 - val_accuracy: 0.7124\n",
      "Epoch 71/200\n",
      "29/29 [==============================] - 21s 710ms/step - loss: 0.0485 - accuracy: 0.9837 - val_loss: 1.4000 - val_accuracy: 0.7222\n",
      "Epoch 72/200\n",
      "29/29 [==============================] - 21s 717ms/step - loss: 0.0463 - accuracy: 0.9826 - val_loss: 0.9936 - val_accuracy: 0.7320\n",
      "Epoch 73/200\n",
      "29/29 [==============================] - 21s 714ms/step - loss: 0.0475 - accuracy: 0.9847 - val_loss: 0.8224 - val_accuracy: 0.7549\n",
      "Epoch 74/200\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.0442 - accuracy: 0.9869 - val_loss: 1.0279 - val_accuracy: 0.7059\n",
      "Epoch 75/200\n",
      "29/29 [==============================] - 21s 713ms/step - loss: 0.0453 - accuracy: 0.9869 - val_loss: 1.7807 - val_accuracy: 0.5196\n",
      "Epoch 76/200\n",
      "29/29 [==============================] - 21s 715ms/step - loss: 0.0384 - accuracy: 0.9869 - val_loss: 1.7431 - val_accuracy: 0.5621\n",
      "Epoch 77/200\n",
      "29/29 [==============================] - 21s 716ms/step - loss: 0.0555 - accuracy: 0.9847 - val_loss: 1.3258 - val_accuracy: 0.7092\n",
      "Epoch 78/200\n",
      "29/29 [==============================] - 21s 715ms/step - loss: 0.0408 - accuracy: 0.9826 - val_loss: 1.0298 - val_accuracy: 0.7516\n",
      "Epoch 79/200\n",
      "29/29 [==============================] - 21s 718ms/step - loss: 0.0415 - accuracy: 0.9858 - val_loss: 0.9233 - val_accuracy: 0.7549\n",
      "Epoch 80/200\n",
      "29/29 [==============================] - 21s 717ms/step - loss: 0.0344 - accuracy: 0.9902 - val_loss: 0.9057 - val_accuracy: 0.7549\n",
      "Epoch 81/200\n",
      "29/29 [==============================] - 21s 737ms/step - loss: 0.0488 - accuracy: 0.9815 - val_loss: 0.9364 - val_accuracy: 0.7582\n",
      "Epoch 82/200\n",
      "29/29 [==============================] - 21s 722ms/step - loss: 0.0266 - accuracy: 0.9902 - val_loss: 1.1217 - val_accuracy: 0.7418\n",
      "Epoch 83/200\n",
      "29/29 [==============================] - 24s 824ms/step - loss: 0.0441 - accuracy: 0.9826 - val_loss: 1.2842 - val_accuracy: 0.7288\n",
      "Epoch 84/200\n",
      "29/29 [==============================] - 30s 1s/step - loss: 0.0187 - accuracy: 0.9924 - val_loss: 1.4050 - val_accuracy: 0.7255\n",
      "Epoch 85/200\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 0.0417 - accuracy: 0.9924 - val_loss: 1.4607 - val_accuracy: 0.7288\n",
      "Epoch 86/200\n",
      "29/29 [==============================] - 21s 719ms/step - loss: 0.0283 - accuracy: 0.9924 - val_loss: 1.3623 - val_accuracy: 0.7288\n",
      "Epoch 87/200\n",
      "29/29 [==============================] - 22s 757ms/step - loss: 0.0446 - accuracy: 0.9837 - val_loss: 1.3831 - val_accuracy: 0.6830\n",
      "Epoch 88/200\n",
      "20/29 [===================>..........] - ETA: 8s - loss: 0.0212 - accuracy: 0.9922"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.optimizers.experimental import Adagrad\n",
    "from tensorflow.keras.optimizers.schedules import ExponentialDecay\n",
    "\n",
    "number_of_classes = classes.size\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=30, min_delta=0.001, start_from_epoch=15, restore_best_weights=True)\n",
    "epochs = 200\n",
    "dropout_rate = 0.4\n",
    "\n",
    "def kaggle_model(optimizer):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Input(shape=image_shape))\n",
    "    model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "    model.add(tf.keras.layers.BatchNormalization())\n",
    "    model.add(tf.keras.layers.Dropout(dropout_rate))\n",
    "    model.add(tf.keras.layers.Dense(number_of_classes, activation='softmax'))\n",
    "    model.compile(optimizer=optimizer, loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "    return model\n",
    "\n",
    "s = 130 * len(X_train) // 32 # number of steps in 130 epochs (batch size = 32)\n",
    "exp_decay_sgd_adagrad = ExponentialDecay(0.01, s, 0.1)\n",
    "exp_adam = ExponentialDecay(0.1, s, 0.95, staircase=True)\n",
    "\n",
    "momentum = 0.99\n",
    "sgd_exp = SGD(exp_decay_sgd_adagrad, momentum=momentum)\n",
    "adam_exp = Adam(exp_adam)\n",
    "adagrad_exp = Adagrad(exp_decay_sgd_adagrad)\n",
    "\n",
    "sgd = SGD(0.001, momentum=momentum)\n",
    "adam = Adam(0.001)\n",
    "adagrad = Adagrad(0.001)\n",
    "\n",
    "optimizers = {\"sgd_exp\": sgd_exp, \"adam_exp\": adam_exp, \"adagrad_exp\": adagrad_exp, \"sgd\": sgd, \"adam\": adam, \"adagrad\": adagrad}\n",
    "\n",
    "\n",
    "histories_with_params = list()\n",
    "\n",
    "for optimizer_name, optimizer in optimizers.items():\n",
    "    model = kaggle_model(optimizer)\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=32,\n",
    "        workers=1, # workers are number of cores\n",
    "        callbacks=early_stopping,\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1)\n",
    "    model.save(\"cnn_files/model.h5\", overwrite=True)\n",
    "    history_with_param = {\"optimizer\": optimizer_name, \"history\": history}\n",
    "    histories_with_params.append(history_with_param)\n",
    "\n",
    "number_of_epochs = len(history.history[\"accuracy\"])\n",
    "for history_with_param in histories_with_params:\n",
    "    plt.plot(history_with_param[\"history\"].history[\"accuracy\"], label=\"train_data accuracy\")\n",
    "    plt.plot(history_with_param[\"history\"].history[\"val_accuracy\"], label=\"val_data accuracy\")\n",
    "    plt.scatter(number_of_epochs, model.evaluate(X_test, y_test)[1], label=\"test_data accuracy\", marker=\"x\", c=\"g\")\n",
    "    plt.title(f\"opt: {history_with_param['optimizer']} Test Score: {round(model.evaluate(X_test, y_test)[1], 2)}%\")\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc=\"upper left\")\n",
    "    plt.savefig(f\"./cnn_files/{history_with_param['optimizer']}.png\",dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(307,)\n",
      "Trying out 300 different combination.\n",
      "Now training model with bs=8, ls=0.01, kn=(3, 3)x(3, 3), ft=32x32, nn=256x128x64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 16:12:09.389877: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5/115 [>.............................] - ETA: 5s - loss: 29.6231 - accuracy: 0.2500 - f1_score: 0.2698   WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0133s vs `on_train_batch_end` time: 0.0278s). Check your callbacks.\n",
      " 27/115 [======>.......................] - ETA: 4s - loss: 23.5991 - accuracy: 0.3148 - f1_score: 0.2694"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)\n",
    "\n",
    "batch_sizes = [8, 16, 32, 64, 128]\n",
    "learning_rates = [0.01, 0.001, 0.0001, 0.00001, 0.000001]\n",
    "conv_kernel_sizes = [[(3,3), (3, 3)],[(7,7), (3, 3)],[(11,11), (3, 3)]] # schauen, ob ggf. wir mehr layer benutzen\n",
    "conv_filter_nums = [[32,32],[32, 64],[64,64],[64,32]]\n",
    "number_of_neurons = [[256, 128, 64]]\n",
    "histories_with_params = list()\n",
    "\n",
    "test_list = product(batch_sizes, learning_rates, conv_kernel_sizes, conv_filter_nums, number_of_neurons)\n",
    "print(f\"Trying out {len(test_list)} different combination.\")\n",
    "# do again cause list\n",
    "test_list = product(batch_sizes, learning_rates, conv_kernel_sizes, conv_filter_nums, number_of_neurons)\n",
    "\n",
    "for batch_size, learning_rate, conv_kernel_size, conv_filter_num, number_of_neuron in test_list:\n",
    "    print(f\"Now training model with bs={batch_size}, ls={learning_rate}, kn={conv_kernel_size[0]}x{conv_kernel_size[1]}, ft={conv_filter_num[0]}x{conv_filter_num[1]}, nn={number_of_neuron[0]}x{number_of_neuron[1]}x{number_of_neuron[2]}\")\n",
    "    model = create_model(conv_kernel_size, conv_filter_num,number_of_neuron)\n",
    "    #model.summary()\n",
    "    history = model.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        #workers=8, # workers are number of cores\n",
    "        callbacks=[early_stopping,ClearMemory()],\n",
    "        validation_data=(X_val, y_val),\n",
    "        verbose=1)\n",
    "    \n",
    "    #parameters = {\n",
    "    #    \"bs\": batch_size, \n",
    "    #    \"lr\": learning_rate,\n",
    "    #    \"kn\": conv_kernel_size,\n",
    "    #    \"ft\": conv_filter_num,\n",
    "    #    \"nn\": number_of_neuron,\n",
    "    #    \"ts\": round(model.evaluate(X_test, y_test)[1], 2)*100\n",
    "    #}\n",
    "    \n",
    "    #history_with_param = {\"history\": history, \"parameters\": parameters}\n",
    "    #\n",
    "    #histories_with_params.append(history_with_param)\n",
    "    # too clear cache?\n",
    "    model.save(f'./t/a.keras',overwrite=True)\n",
    "\n",
    "    #print(f\"Epochs: {len(history.history['accuracy'])}\")\n",
    "    #print(f\"Test Score: {round(model.evaluate(X_test, y_test)[1], 2)}%\")\n",
    "    tf.compat.v1.reset_default_graph()\n",
    "    tf.keras.backend.clear_session()\n",
    "    del model\n",
    "    gc.collect()\n",
    "    #reset_keras()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#number_of_epochs = len(history.history[\"accuracy\"])\n",
    "\n",
    "#for history_with_param in histories_with_params:\n",
    "    #model = load_model(f\"./cnn_files/cnn_bs{\n",
    "    #    history_with_param['parameters']['bs']\n",
    "    #    }_ls{\n",
    "    #    history_with_param['parameters']['lr']\n",
    "    #    }_kn{\n",
    "    #    history_with_param['parameters']['kn'][0]\n",
    "    #    }x{\n",
    "    #    history_with_param['parameters']['kn'][1]\n",
    "    #    }_ft{\n",
    "    #    history_with_param['parameters']['ft'][0]\n",
    "    #    }x{\n",
    "    #    history_with_param['parameters']['ft'][1]\n",
    "    #    }_nn{\n",
    "    #    history_with_param['parameters']['nn'][0]\n",
    "    #    }x{\n",
    "    #    history_with_param['parameters']['nn'][1]\n",
    "    #    }x{\n",
    "    #    history_with_param['parameters']['nn'][2]\n",
    "    #    }.keras\")\n",
    "    \n",
    "#    plt.plot(history_with_param[\"history\"].history[\"val_accuracy\"], label=\"val_data accuracy\")\n",
    "#    plt.plot(history_with_param[\"history\"].history[\"accuracy\"], label=\"train_data accuracy\")\n",
    "#    \n",
    "#    plt.scatter(number_of_epochs, model.evaluate(X_test, y_test)[1], label=\"test_data accuracy\", marker=\"x\", c=\"g\")\n",
    "#    plt.title(f\"bs{\n",
    "#        history_with_param['parameters']['bs']\n",
    "##        } ls{\n",
    "#        history_with_param['parameters']['lr']\n",
    "#        }\\nkn{\n",
    "#        history_with_param['parameters']['kn'][0]\n",
    "#        }x{\n",
    "#        history_with_param['parameters']['kn'][1]\n",
    "#        } ft{\n",
    "#        history_with_param['parameters']['ft'][0]\n",
    "#        }x{\n",
    " #       history_with_param['parameters']['ft'][1]\n",
    " ##       }\\nnn{\n",
    " #       history_with_param['parameters']['nn'][0]\n",
    " #       }x{\n",
    "  #      history_with_param['parameters']['nn'][1]\n",
    "#        }x{\n",
    "#        history_with_param['parameters']['nn'][2]\n",
    "#        }\\nts{\n",
    "#        history_with_param['parameters']['ts']\n",
    "#        }\")\n",
    "#    plt.xlabel(\"Epochs\")\n",
    "#    plt.ylabel(\"Accuracy\")\n",
    "#    plt.legend(loc=\"lower right\")\n",
    "#    plt.savefig(f\"./cnn_files/cnn_bs{\n",
    "#        history_with_param['parameters']['bs']\n",
    "#        }_ls{\n",
    "#        history_with_param['parameters']['lr']\n",
    "#        }_kn{\n",
    "#        history_with_param['parameters']['kn'][0]\n",
    "#        }x{\n",
    "##        history_with_param['parameters']['kn'][1]\n",
    "#        }_ft{\n",
    "##        history_with_param['parameters']['ft'][0]\n",
    "#        }x{\n",
    "#        history_with_param['parameters']['ft'][1]\n",
    "#        }_nn{\n",
    "#        history_with_param['parameters']['nn'][0]\n",
    "#        }x{\n",
    " #       history_with_param['parameters']['nn'][1]\n",
    " #       }x{\n",
    "#       history_with_param['parameters']['nn'][2]\n",
    "#        }.keras\",dpi=200)\n",
    "#    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints n=|base_group| figures with subplots, based on the other paramters\n",
    "def print_results(base_group: (str,list), histories_all: list, number_of_epochs: int) -> None:\n",
    "    # for everx value of base group create figure, and than create subplots based on how many paramters there are\n",
    "    for val in base_group[1]:\n",
    "        # get all histires with said value\n",
    "        histories = [his for his in histories_all if his['parameters'][base_group[0]]==val]    \n",
    "        # Compute Rows required\n",
    "        total = len(base_group[1])\n",
    "        cols = int((total)**0.5)\n",
    "        rows = total // cols\n",
    "        if total % cols != 0:\n",
    "            rows += 1\n",
    "        pos = range(1,total+1)\n",
    "        \n",
    "        # plot\n",
    "        fig = plt.figure(figsize=(15,10))\n",
    "        for i in range(0,len(histories)):\n",
    "            # load model\n",
    "            model = load_model(f\"./cnn_files/cnn_bs{histories[i]['parameters']['bs']}_ls{histories[i]['parameters']['lr']}.keras\")\n",
    "            # get test score\n",
    "            test_score = round(model.evaluate(X_test, y_test)[1], 2)*100\n",
    "            # make a new subplot for every history\n",
    "            ax = fig.add_subplot(rows,cols,pos[i])\n",
    "            ax.set_ylim([0,1])\n",
    "            ax.set_xlim([0,number_of_epochs])\n",
    "            ax.plot(histories[i][\"history\"].history[\"val_accuracy\"], label=\"val_data accuracy\")\n",
    "            ax.plot(histories[i][\"history\"].history[\"accuracy\"], label=\"train_data accuracy\")\n",
    "            ax.set_title(f\"{base_group[0]}: {histories[i]['parameters'][base_group[0]]} lr: {histories[i]['parameters']['lr']}, Test Score: {test_score}%\")\n",
    "            ax.set_xlabel(\"Epochs\")\n",
    "            ax.set_ylabel(\"Accuracy\")\n",
    "            ax.legend(loc=\"lower right\")\n",
    "        plt.savefig(f\"t/{val}_a.png\")        \n",
    "        plt.show()\n",
    "        plt.close()\n",
    "\n",
    "print_results(('bs',batch_sizes),histories_with_params,150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tf.keras.backend.clear_session()\n",
    "#gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get memory usage\n",
    "\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted_vars = sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)\n",
    "\n",
    "sorted_vars_in_gb = [(var, size / (1024 ** 3)) for var, size in sorted_vars]\n",
    "sorted_vars_in_gb\n",
    "total_memory = sum(size for _, size in sorted_vars)\n",
    "total_memory_in_gb = total_memory / (1024 ** 3)\n",
    "total_memory_in_gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
