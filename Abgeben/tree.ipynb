{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis:** Da bei Tree-Modellen der Input in einen eindimensionalen Vektor vorliegt, gehen Zusammenhangsstrukturen nebeneinanderliegender Pixel verloren. Aus diesem Grund stellt diese Art von Netzwerk eine falsche Modelklasse für unser Problem dar. Wir haben es zur Veranschaulichung und der Aufgabenstellung trotzdem kurz gezeigt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Daten einlesen\n",
    "\n",
    "**Hinweis:** Die Daten wurden in einer pkl-Datei gespeichert, um nicht jedes mal die Vorverarbeitung durchführen zu müssen und unkompliziert zwischen den Modelklassen hin- und her wechseln zu können"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./data/images_df_numerical.pkl')\n",
    "classes = data[\"Species\"].unique()\n",
    "number_of_classes = classes.size\n",
    "X, y = data['data'], data['Species']\n",
    "X, y = np.stack(X).astype(np.float16), y.to_numpy().astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis:** Im Folgenden wird ausschließlich der CART-Algorithmus verwendet, da dieser Binärbäume erstellt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Funktion für einfachen Decision Tree\n",
    "Mit den folgenden Funktionen können einfache Entscheidungsbäume erstellt und ausgewertet werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_tree(X_train, y_train, max_depth=1, criterion=\"gini\", min_samples_leaf=4):\n",
    "    tree = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion)\n",
    "    tree.fit(X_train,y_train)\n",
    "\n",
    "    return tree\n",
    "\n",
    "def evaluate_model(model, X_train, y_train, X_test, y_test,):\n",
    "    # Predictions\n",
    "    y_hat_tr = model.predict(X_train)\n",
    "    y_hat_test = model.predict(X_test)\n",
    "\n",
    "    #Accuracy Score\n",
    "    tr_score = model.score(X_train, y_train, sample_weight=None)\n",
    "    test_score = model.score(X_test, y_test, sample_weight=None)\n",
    "    \n",
    "    # F1 Score\n",
    "    f1_tr_score = f1_score(y_train, y_hat_tr, average='weighted')\n",
    "    f1_test_score = f1_score(y_test, y_hat_test, average='weighted')\n",
    "\n",
    "\n",
    "    return  tr_score, test_score,  f1_tr_score, f1_test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Einfacher Decision Trees\n",
    "Im Folgenden werden verschiedene Hyperparameter getestet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "max_depth_values = range(1,20)\n",
    "criterion_values = [\"gini\", \"entropy\"]\n",
    "\n",
    "train_acc_dict = dict()\n",
    "test_acc_dict = dict()\n",
    "f1_train_dict = dict()\n",
    "f1_test_dict = dict()\n",
    "\n",
    "for depth in tqdm(max_depth_values):\n",
    "    for criterion in tqdm(criterion_values):\n",
    "        # Trainings- und Testdaten aufteilen\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)\n",
    "        \n",
    "        # Modell trainieren\n",
    "        model = fit_tree(X_train, y_train, max_depth=depth, criterion=criterion)\n",
    "        \n",
    "        # Modell evaluieren\n",
    "        train_acc, test_acc, f1_train, f1_test = evaluate_model(model, X_train, y_train, X_test, y_test)\n",
    "        \n",
    "        # Ergebnisse speichern\n",
    "        train_acc_dict[(depth, criterion)] = train_acc\n",
    "        test_acc_dict[(depth, criterion)] = test_acc\n",
    "       \n",
    "        f1_train_dict[(depth, criterion)] = f1_train\n",
    "        f1_test_dict[(depth, criterion)] = f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plotten der Scores\n",
    "Im Folgenden werden die zuvor erstellten Bäume geplottet. Dadurch kann leicht erkannt werden, wie die Bäume auf die jeweiligen Daten performen (overfitting)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "depths = range(1, 20)\n",
    "criterion_values = [\"gini\", \"entropy\"]\n",
    "\n",
    "# Extrahiere die Test- und Trainingsgenauigkeiten für die verschiedenen Kriterien\n",
    "train_accs_gini = [train_acc_dict[(depth, 'gini')] for depth in depths]\n",
    "test_accs_gini = [test_acc_dict[(depth, 'gini')] for depth in depths]\n",
    "\n",
    "train_accs_entropy = [train_acc_dict[(depth, 'entropy')] for depth in depths]\n",
    "test_accs_entropy = [test_acc_dict[(depth, 'entropy')] for depth in depths]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depths, train_accs_gini, marker='o', label='Train accuracy (gini)')\n",
    "plt.plot(depths, test_accs_gini, marker='o', label='Test accuracy (gini)')\n",
    "plt.plot(depths, train_accs_entropy, marker='o', label='Train accuracy (entropy)')\n",
    "plt.plot(depths, test_accs_entropy, marker='o', label='Test accuracy (entropy)')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy for Different Max Depths and Criteria')\n",
    "plt.xticks(np.arange(1, 20, step=1))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### F1-Score\n",
    "\n",
    "**Hinweis:** Das Model ordnet einfach die meisten Punkte zu der größten Klasse zu, was beim F1-Score anders als bei der Accuracy bestraft wird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#F1 Score\n",
    "train_f1_gini = [f1_train_dict[(depth, 'gini')] for depth in depths]\n",
    "test_f1_gini = [f1_test_dict[(depth, 'gini')] for depth in depths]\n",
    "\n",
    "train_f1_entropy = [train_acc_dict[(depth, 'entropy')] for depth in depths]\n",
    "test_f1_entropy = [f1_test_dict[(depth, 'entropy')] for depth in depths]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(depths, train_f1_gini, marker='o', label='Train accuracy (gini)')\n",
    "plt.plot(depths, test_f1_gini, marker='o', label='Test accuracy (gini)')\n",
    "plt.plot(depths, train_f1_entropy, marker='o', label='Train accuracy (entropy)')\n",
    "plt.plot(depths, test_f1_entropy, marker='o', label='Test accuracy (entropy)')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('F1')\n",
    "plt.title('F1-Score for Different Max Depths and Criteria')\n",
    "plt.xticks(np.arange(1, 20, step=1))\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis:** Mit zunehmender Tiefe ist ein zunehmendes overfitting zu erkennen. Um dies zu vermindern wäre die Wahl der richtigen Hyperparameter nötig.(max_depth, min_samples_split, min_samples_leaf, max_leaf_nodes) Dies wurde auch vereinzelt getestet, aber da es sich um eine falsche Modellklasse handelt, haben wir uns eher auf das CNN und die Datenvorverarbeitung konzentriert."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### k-Fold-Cross-Validation\n",
    "\n",
    "Wir benutzen 10-Fold-Cross-Validation, um das Ergebnis weniger vom gewählten Split abhängig zu machen und somit das Ergebnis zu stabilisieren. Statified stellt sicher, dass die Klasseneinteilung beibehalten wird. Dies ist vor allem ohne Resampling interessant, da wir extrem ungleich verteilte Klassen haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Random Forest\n",
    "Wir versuchen mit einer Ensemble-Methode das Ergebnis zu verbessern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter\n",
    "i_estimators = range(1, 250, 25)\n",
    "leaf_nodes = range(2, 16, 2)\n",
    "\n",
    "random_train_acc_dict = dict()\n",
    "random_test_acc_dict = dict()\n",
    "random_f1_train_dict = dict()\n",
    "random_f1_test_dict = dict()\n",
    "\n",
    "for estimators in tqdm(i_estimators):\n",
    "    for nodes in tqdm(leaf_nodes):\n",
    "        train_acc_list, test_acc_list, f1_train_list, f1_test_list = list(), list(), list(), list()\n",
    "\n",
    "        for train_idx, test_idx in kfold.split(X_train, y_train):\n",
    "            rnd_clf = RandomForestClassifier(n_estimators=estimators, max_leaf_nodes=nodes, n_jobs=-1)\n",
    "            rnd_clf.fit(X_train[train_idx], y_train[train_idx])\n",
    "\n",
    "            train_acc, test_acc, f1_train, f1_test = evaluate_model(rnd_clf, X_train[train_idx], y_train[train_idx],\n",
    "                                                                   X_train[test_idx], y_train[test_idx])\n",
    "\n",
    "            train_acc_list.append(train_acc)\n",
    "            test_acc_list.append(test_acc)\n",
    "            f1_train_list.append(f1_train)\n",
    "            f1_test_list.append(f1_test)\n",
    "\n",
    "        mean_train_acc = np.mean(train_acc_list)\n",
    "        mean_test_acc = np.mean(test_acc_list)\n",
    "        mean_f1_train = np.mean(f1_train_list)\n",
    "        mean_f1_test = np.mean(f1_test_list)\n",
    "\n",
    "        random_train_acc_dict[(estimators, nodes)] = mean_train_acc\n",
    "        random_test_acc_dict[(estimators, nodes)] = mean_test_acc\n",
    "        random_f1_train_dict[(estimators, nodes)] = mean_f1_train\n",
    "        random_f1_test_dict[(estimators, nodes)] = mean_f1_test\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Auswertung des Trainings- und Testprozesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Um die Ergebnisse plotten zu können, werden sie in Listen umgewandelt\n",
    "estimators_list = list(i_estimators)\n",
    "leaf_nodes_list = list(leaf_nodes)\n",
    "\n",
    "train_accuracy_array = np.array([[random_train_acc_dict[(est, node)] for node in leaf_nodes_list] for est in estimators_list])\n",
    "test_accuracy_array = np.array([[random_test_acc_dict[(est, node)] for node in leaf_nodes_list] for est in estimators_list])\n",
    "\n",
    "# Erstelle ein Konturlinien-Diagramm für Trainingsgenauigkeit\n",
    "plt.figure(figsize=(10, 6))\n",
    "contour = plt.contourf(leaf_nodes_list, estimators_list, train_accuracy_array, cmap='viridis')\n",
    "plt.colorbar(contour, label='Trainingsgenauigkeit')\n",
    "plt.xlabel('Max Leaf Nodes')\n",
    "plt.ylabel('Number of Estimators')\n",
    "plt.title('Trainingsgenauigkeit für verschiedene Parameter')\n",
    "plt.xticks(leaf_nodes_list)\n",
    "plt.yticks(estimators_list)\n",
    "plt.grid(visible=True)\n",
    "plt.show()\n",
    "\n",
    "# Erstelle ein Konturlinien-Diagramm für Testgenauigkeit\n",
    "plt.figure(figsize=(10, 6))\n",
    "contour = plt.contourf(leaf_nodes_list, estimators_list, test_accuracy_array, cmap='viridis')\n",
    "plt.colorbar(contour, label='Testgenauigkeit')\n",
    "plt.xlabel('Max Leaf Nodes')\n",
    "plt.ylabel('Number of Estimators')\n",
    "plt.title('Testgenauigkeit für verschiedene Parameter')\n",
    "plt.xticks(leaf_nodes_list)\n",
    "plt.yticks(estimators_list)\n",
    "plt.grid(visible=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hinweis:** Bei der verwendeten Gittersuche ist erkannbar, dass durch die Regulierung der maximalen Blätter und der steigenden Anzahl von verwendeten Bäumen, nur leichte Veränderung erkennbar sind. \n",
    "Nur an den unteren Rändern, der Grafiken, ist eine Veränderung der Test- und Trainingsgenauigkeit erkennbar. Das Modell zeigt:  Hier findet eine Überanpassung statt, dadruch steigt zwar die Trainingsgenauigkeit, einher stinkt jeoch die Testgenauigkeit.\n",
    "\n",
    "**Auswertung:**\n",
    "Trotz der Regeulierungen kann kein herausstechendes Modell mit passenden Paramtern gefunden werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Extra Trees -  Extremly Randomized Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eine Abwandlung des Random Forrest, welche aber die Feature-Seperation-Trashholds auch zufällig wählt => weniger overfitting durch diversere Bäume."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [02:27<00:00, 18.45s/it]\n",
      "100%|██████████| 8/8 [03:08<00:00, 23.55s/it]t]\n",
      "100%|██████████| 8/8 [46:14<00:00, 346.87s/it]]\n",
      "100%|██████████| 8/8 [03:29<00:00, 26.25s/it]s/it]\n",
      "100%|██████████| 8/8 [04:08<00:00, 31.02s/it]/it] \n",
      " 50%|█████     | 5/10 [59:29<55:44, 668.92s/it]  "
     ]
    }
   ],
   "source": [
    "# Hyperparameter\n",
    "i_estimators = range(1, 250, 25)\n",
    "leaf_nodes = range(2, 16, 2)\n",
    "\n",
    "extra_train_acc_dict = dict()\n",
    "extra_test_acc_dict = dict()\n",
    "extra_f1_train_dict = dict()\n",
    "extra_f1_test_dict = dict()\n",
    "\n",
    "for estimators in tqdm(i_estimators):\n",
    "    for nodes in tqdm(leaf_nodes):\n",
    "        train_acc_list, test_acc_list, f1_train_list, f1_test_list = list(), list(), list(), list()\n",
    "\n",
    "        for train_idx, test_idx in kfold.split(X_train, y_train):\n",
    "            rnd_clf = ExtraTreesClassifier(n_estimators=estimators, max_leaf_nodes=nodes, n_jobs=-1)\n",
    "            rnd_clf.fit(X_train[train_idx], y_train[train_idx])\n",
    "\n",
    "            train_acc, test_acc, f1_train, f1_test = evaluate_model(rnd_clf, X_train[train_idx], y_train[train_idx],\n",
    "                                                                   X_train[test_idx], y_train[test_idx])\n",
    "\n",
    "            train_acc_list.append(train_acc)\n",
    "            test_acc_list.append(test_acc)\n",
    "            f1_train_list.append(f1_train)\n",
    "            f1_test_list.append(f1_test)\n",
    "\n",
    "        mean_train_acc = np.mean(train_acc_list)\n",
    "        mean_test_acc = np.mean(test_acc_list)\n",
    "        mean_f1_train = np.mean(f1_train_list)\n",
    "        mean_f1_test = np.mean(f1_test_list)\n",
    "\n",
    "        extra_train_acc_dict[(estimators, nodes)] = mean_train_acc\n",
    "        extra_test_acc_dict[(estimators, nodes)] = mean_test_acc\n",
    "        extra_f1_train_dict[(estimators, nodes)] = mean_f1_train\n",
    "        extra_f1_test_dict[(estimators, nodes)] = mean_f1_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Auswertung des Trainings- und Testprozesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Um die Ergebnisse plotten zu können, müssen wir die Daten in Listen umwandeln\n",
    "estimators_list = list(i_estimators)\n",
    "leaf_nodes_list = list(leaf_nodes)\n",
    "\n",
    "train_accuracy_array = np.array([[extra_train_acc_dict[(est, node)] for node in leaf_nodes_list] for est in estimators_list])\n",
    "test_accuracy_array = np.array([[extra_test_acc_dict[(est, node)] for node in leaf_nodes_list] for est in estimators_list])\n",
    "\n",
    "# Erstelle ein Konturlinien-Diagramm für Trainingsgenauigkeit\n",
    "plt.figure(figsize=(10, 6))\n",
    "contour = plt.contourf(leaf_nodes_list, estimators_list, train_accuracy_array, cmap='viridis')\n",
    "plt.colorbar(contour, label='Trainingsgenauigkeit')\n",
    "plt.xlabel('Max Leaf Nodes')\n",
    "plt.ylabel('Number of Estimators')\n",
    "plt.title('Trainingsgenauigkeit für verschiedene Parameter')\n",
    "plt.xticks(leaf_nodes_list)\n",
    "plt.yticks(estimators_list)\n",
    "plt.grid(visible=True)\n",
    "plt.show()\n",
    "\n",
    "# Erstelle ein Konturlinien-Diagramm für Testgenauigkeit\n",
    "plt.figure(figsize=(10, 6))\n",
    "contour = plt.contourf(leaf_nodes_list, estimators_list, test_accuracy_array, cmap='viridis')\n",
    "plt.colorbar(contour, label='Testgenauigkeit')\n",
    "plt.xlabel('Max Leaf Nodes')\n",
    "plt.ylabel('Number of Estimators')\n",
    "plt.title('Testgenauigkeit für verschiedene Parameter')\n",
    "plt.xticks(leaf_nodes_list)\n",
    "plt.yticks(estimators_list)\n",
    "plt.grid(visible=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auswertung:** Die Grafiken unterschieden sich kaum im Vergleich zu Random Forest. \n",
    "\n",
    "**Hinweis:** Der Eintausch von Bias gegen Varianz zeigt keine erwähnbaren Unterschiede => Klassenverteilung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Boosting\n",
    "\n",
    "**Hinweis:** Vorab ist zu erwähnen, dass die Modelle schlechte Ergebnisse erzielen, da sie sich \"das Leben zu einfach machen\". Durch die Ungleichgewichtung der Klassen in den Daten und den Verlust der Struktur durch das Flatten ordnen die Boosting-Modelle alle Feldermausbilder der größten Klasse zu. Dies führt zu vermeintlich guten Ergebnissen, die jedoch trügerisch sind (was sich auch in den Konfusionsmatrizen widerspiegelt.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nachfolgend sind  AdaBoost und Gradient Boosting zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf = AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200, algorithm=\"SAMME.R\", learning_rate=0.7)\n",
    "ada_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_clf_train = ada_clf.predict(X_train)\n",
    "ada_clf_test = ada_clf.predict(X_test)\n",
    "\n",
    "train_accuracy = accuracy_score(y_train, ada_clf_train)\n",
    "test_accuracy = accuracy_score(y_test, ada_clf_test)\n",
    "\n",
    "train_f1 = f1_score(y_train, ada_clf_train, average='weighted')\n",
    "test_f1 = f1_score(y_test, ada_clf_test, average='weighted')\n",
    "\n",
    "labels = ['Train', 'Test']\n",
    "\n",
    "print(\"Train F1 Score:\", train_f1)\n",
    "print(\"Test F1 Score:\", test_f1)\n",
    "print(\"train_accuracy\", train_accuracy )\n",
    "print(\"test_accuracy\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Auswertung** AdaBoostClassifier liefert keine erheblich besseren Werte als die Verfahren zuvor. Der Test und Training F1-Score weicht von den anderen Baum-Modellen kaum ab.\n",
    "\n",
    "\n",
    "**Hinweis:** Bei großer Learning-Rate ist die Rechenzeit des AdaBoostClassifier relativ kurz, da einfach nur immer die erste Klasse vorhergesagt wird. Dies war auch bei kleinerer Learning-Rate der Fall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingClassifier(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_test, y_pred) for y_pred in gbrt.staged_predict(X_test)]\n",
    "bst_n_estimators = np.argmin(errors)\n",
    "\n",
    "gbrt_best = GradientBoostingClassifier(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = [mean_squared_error(y_test, y_pred) for y_pred in gbrt.staged_predict(X_test)]\n",
    "bst_n_estimators = np.argmin(errors) + 1\n",
    "gbrt_best = GradientBoostingClassifier(max_depth=2, n_estimators=bst_n_estimators)\n",
    "gbrt_best.fit(X_train, y_train)\n",
    "\n",
    "y_pred = gbrt_best.predict(X_test)\n",
    "\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(errors) + 1), errors, label='MSE auf Testdaten')\n",
    "plt.axvline(bst_n_estimators, linestyle='--', color='red', label='Beste Anzahl von Schätzungen')\n",
    "plt.xlabel('Anzahl der Schätzungen')\n",
    "plt.ylabel('Mittlere quadratische Abweichung (MSE)')\n",
    "plt.legend()\n",
    "plt.title('Entwicklung des MSE mit der Anzahl der Schätzungen')\n",
    "plt.show()\n",
    "\n",
    "print(\"Beste Anzahl von Schätzungen:\", bst_n_estimators)\n",
    "print(\"Gewichteter F1-Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Confusion Matrix\n",
    "\n",
    "Man kann sehen, dass das Modell nichts gelernt hat, sondern einfach nur immer die erste Klasse vorhersagt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(y_test, y_pred)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix, display_labels=classes)\n",
    "cm_display.plot(ax=ax, cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
